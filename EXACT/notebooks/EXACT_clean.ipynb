{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e2c26-1130-4cae-993f-b20dea629f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# S0. Imports & paths\n",
    "# =======================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Root folder for outputs (figures, CSVs, etc.)\n",
    "OUT_ROOT = Path(\"./results/notebook_run\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Root folder where your telemetry CSVs live\n",
    "DATA_ROOT = Path(\"./data/telemetry\")  # <-- set this to your telemetry folder\n",
    "\n",
    "print(\"[S0] DATA_ROOT =\", DATA_ROOT)\n",
    "print(\"[S0] Available CSV files:\")\n",
    "csv_files = sorted(DATA_ROOT.glob(\"*.csv\"))\n",
    "for p in csv_files:\n",
    "    print(\"   -\", p.name)\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Meta columns (used later in S2+)\n",
    "META_COLS_BASE = {\n",
    "    \"setup\",\n",
    "    \"scenario\",\n",
    "    \"workload\",\n",
    "    \"time_idx\",\n",
    "    \"label\",\n",
    "    \"is_anom\",\n",
    "}\n",
    "\n",
    "\n",
    "# =======================\n",
    "# S1. Load telemetry CSVs\n",
    "# =======================\n",
    "\n",
    "def _parse_scenario_workload_from_name(path: Path):\n",
    "    \"\"\"\n",
    "    Expect filenames like:\n",
    "        DDR4_DROOP_dft.csv\n",
    "        DDR4_benign_tr.csv\n",
    "        DDR5_SPECTRE_mm.csv\n",
    "        DDR5_benign_ni.csv\n",
    "    Returns (scenario_str, workload_str).\n",
    "    \"\"\"\n",
    "    stem = path.stem  # e.g., 'DDR4_DROOP_dft'\n",
    "    parts = stem.split(\"_\")\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"Cannot parse scenario/workload from filename: {path.name}\")\n",
    "\n",
    "    # parts[0] = 'DDR4' or 'DDR5'\n",
    "    scen_raw = parts[1]      # e.g., 'DROOP', 'RH', 'SPECTRE', 'benign'\n",
    "    wl_raw = parts[2]        # e.g., 'dft', 'dj', ...\n",
    "\n",
    "    scenario = scen_raw.strip().upper()\n",
    "    if scenario == \"BENIGN\":\n",
    "        scenario = \"BENIGN\"  # normalize (already upper anyway)\n",
    "    # DROOP / RH / SPECTRE are already upper in your names\n",
    "\n",
    "    workload = wl_raw.strip().upper()  # DFT, DJ, ...\n",
    "\n",
    "    return scenario, workload\n",
    "\n",
    "\n",
    "def load_telemetry_for_setup(setup: str, data_root: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a single telemetry DataFrame for a given setup:\n",
    "      - setup='A' -> all DDR4_* CSVs\n",
    "      - setup='B' -> all DDR5_* CSVs\n",
    "\n",
    "    Adds columns:\n",
    "      - setup        ('A' or 'B')\n",
    "      - scenario     ('BENIGN', 'DROOP', 'RH', 'SPECTRE')\n",
    "      - workload     ('DFT', 'DJ', ...)\n",
    "      - time_idx     (0..N-1 within each file)\n",
    "      - is_anom      (0 for BENIGN, 1 for others)\n",
    "      - label        (same as is_anom at sample level)\n",
    "    \"\"\"\n",
    "    if setup.upper() == \"A\":\n",
    "        prefix = \"DDR4_\"\n",
    "    elif setup.upper() == \"B\":\n",
    "        prefix = \"DDR5_\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown setup: {setup}. Expected 'A' or 'B'.\")\n",
    "\n",
    "    files = sorted(data_root.glob(f\"{prefix}*.csv\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"[S1] No files found for setup {setup} with prefix {prefix} in {data_root}\"\n",
    "        )\n",
    "\n",
    "    print(f\"[S1] Loading setup {setup} from {len(files)} files with prefix {prefix}*\")\n",
    "\n",
    "    dfs = []\n",
    "    for path in files:\n",
    "        scenario, workload = _parse_scenario_workload_from_name(path)\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Add meta columns\n",
    "        df[\"setup\"] = setup\n",
    "        df[\"scenario\"] = scenario\n",
    "        df[\"workload\"] = workload\n",
    "\n",
    "        # time_idx: if missing, just use row order within that file\n",
    "        if \"time_idx\" not in df.columns:\n",
    "            df[\"time_idx\"] = np.arange(len(df), dtype=int)\n",
    "\n",
    "        # Labels: BENIGN = 0, all other scenarios = 1\n",
    "        is_anom = 0 if scenario == \"BENIGN\" else 1\n",
    "        df[\"is_anom\"] = is_anom\n",
    "        df[\"label\"] = is_anom\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "        print(\n",
    "            f\"[S1]   {path.name}: scenario={scenario}, workload={workload}, \"\n",
    "            f\"rows={len(df)}\"\n",
    "        )\n",
    "\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Sort for reproducible windowing later\n",
    "    full_df = full_df.sort_values(\n",
    "        [\"workload\", \"scenario\", \"time_idx\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(\n",
    "        f\"[S1] Final telemetry for setup {setup}: \"\n",
    "        f\"{len(full_df)} rows, {full_df.shape[1]} columns.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"[S1]   Scenarios: {sorted(full_df['scenario'].unique())}, \"\n",
    "        f\"Workloads: {sorted(full_df['workload'].unique())}\"\n",
    "    )\n",
    "\n",
    "    return full_df\n",
    "\n",
    "\n",
    "# ---- Load A and B from the folder ----\n",
    "telemetry_A = load_telemetry_for_setup(\"A\", DATA_ROOT)  # DDR4_* -> Setup A\n",
    "telemetry_B = load_telemetry_for_setup(\"B\", DATA_ROOT)  # DDR5_* -> Setup B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b7895-069d-4f53-a0e5-b727f7e711a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# S2. Cleaning & debiasing\n",
    "# ============================\n",
    "\n",
    "def get_feature_columns(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Numeric telemetry columns used as features, excluding meta/label columns.\n",
    "    \"\"\"\n",
    "    meta_cols = set(META_COLS_BASE)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    feature_cols = [c for c in numeric_cols if c not in meta_cols]\n",
    "    return feature_cols\n",
    "\n",
    "\n",
    "def clean_and_debias_telemetry(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simple cleaning + benign debiasing:\n",
    "      - Drop rows with all-NaN numeric features\n",
    "      - Subtract per-feature BENIGN mean (if available)\n",
    "    Returns a new DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    feature_cols = get_feature_columns(df)\n",
    "    if not feature_cols:\n",
    "        raise ValueError(\"No numeric feature columns found for telemetry.\")\n",
    "\n",
    "    # Drop rows where all feature columns are NaN\n",
    "    mask_all_nan = df[feature_cols].isna().all(axis=1)\n",
    "    if mask_all_nan.any():\n",
    "        df = df.loc[~mask_all_nan].reset_index(drop=True)\n",
    "        print(f\"[S2] Dropped {mask_all_nan.sum()} rows with all-NaN features.\")\n",
    "\n",
    "    # Compute benign means (if any BENIGN rows exist)\n",
    "    if \"scenario\" in df.columns:\n",
    "        ben_mask = df[\"scenario\"] == \"BENIGN\"\n",
    "        if ben_mask.any():\n",
    "            benign_means = df.loc[ben_mask, feature_cols].mean(axis=0)\n",
    "            df[feature_cols] = df[feature_cols].fillna(benign_means)\n",
    "            df[feature_cols] = df[feature_cols] - benign_means\n",
    "            print(\n",
    "                f\"[S2] Debiased features using BENIGN mean for \"\n",
    "                f\"{ben_mask.sum()} benign rows.\"\n",
    "            )\n",
    "        else:\n",
    "            # Fallback: use global mean if no BENIGN rows\n",
    "            global_means = df[feature_cols].mean(axis=0)\n",
    "            df[feature_cols] = df[feature_cols].fillna(global_means)\n",
    "            df[feature_cols] = df[feature_cols] - global_means\n",
    "            print(\"[S2] No BENIGN rows; debiased using global feature means.\")\n",
    "    else:\n",
    "        # Very unlikely given S1, but just in case\n",
    "        global_means = df[feature_cols].mean(axis=0)\n",
    "        df[feature_cols] = df[feature_cols].fillna(global_means)\n",
    "        df[feature_cols] = df[feature_cols] - global_means\n",
    "        print(\"[S2] 'scenario' missing; debiased using global feature means.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "telemetry_A_Z = clean_and_debias_telemetry(telemetry_A)\n",
    "telemetry_B_Z = clean_and_debias_telemetry(telemetry_B)\n",
    "\n",
    "feat_A = get_feature_columns(telemetry_A_Z)\n",
    "feat_B = get_feature_columns(telemetry_B_Z)\n",
    "shared_features = sorted(set(feat_A) & set(feat_B))\n",
    "\n",
    "print(f\"[S2] Setup A feature count: {len(feat_A)}\")\n",
    "print(f\"[S2] Setup B feature count: {len(feat_B)}\")\n",
    "print(f\"[S2] Shared features used by CIAS: {len(shared_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61838619-d352-41fc-b57a-ea4d676fb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# S3. CIAS model\n",
    "# =======================\n",
    "\n",
    "@dataclass\n",
    "class CIASModel:\n",
    "    \"\"\"\n",
    "    Lightweight CIAS parameter bundle + scoring functions.\n",
    "\n",
    "    feature_cols : list of feature names (same order as mu/sigma/w)\n",
    "    mu           : benign mean per feature\n",
    "    sigma        : benign std per feature\n",
    "    w            : non-negative weights per feature (sum to 1)\n",
    "    lambda_res   : trade-off between E2(t) and E1(t) in CIAS score\n",
    "    \"\"\"\n",
    "    feature_cols: list\n",
    "    mu: np.ndarray\n",
    "    sigma: np.ndarray\n",
    "    w: np.ndarray\n",
    "    lambda_res: float = 0.5\n",
    "\n",
    "    def _sigma_safe(self) -> np.ndarray:\n",
    "        \"\"\"Avoid divide-by-zero in normalization.\"\"\"\n",
    "        return np.where(self.sigma <= 1e-6, 1.0, self.sigma)\n",
    "\n",
    "    def score_array(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Compute (score, E1, E2) for a 2D array X of shape (n_samples, n_features).\n",
    "        \"\"\"\n",
    "        s = self._sigma_safe()\n",
    "        Z = (X - self.mu) / s\n",
    "\n",
    "        # E2: weighted variance-normalized squared distance (Euclidean-type)\n",
    "        E2 = np.sum(self.w * (Z ** 2), axis=1)\n",
    "\n",
    "        # E1: weighted sum of absolute shifts (L1-type residual mass)\n",
    "        E1 = np.sum(self.w * np.abs(Z), axis=1)\n",
    "\n",
    "        score = (1.0 - self.lambda_res) * E2 + self.lambda_res * E1\n",
    "        return score, E1, E2\n",
    "\n",
    "    def score_dataframe(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Convenience wrapper for DataFrames with matching feature columns.\n",
    "        \"\"\"\n",
    "        X = df[self.feature_cols].to_numpy(dtype=float)\n",
    "        return self.score_array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2114461-ce18-4cd3-9719-cc7834b1c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# S4. Fit CIAS from BENIGN\n",
    "# ============================\n",
    "\n",
    "def fit_cias_from_benign(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    lambda_res: float = 0.5,\n",
    ") -> CIASModel:\n",
    "    \"\"\"\n",
    "    Fit a CIASModel using only BENIGN rows:\n",
    "      - mu, sigma from benign feature statistics\n",
    "      - weights w_f from inverse benign variance (larger weight for\n",
    "        more stable / less noisy features).\n",
    "    \"\"\"\n",
    "    if \"scenario\" not in df.columns:\n",
    "        raise KeyError(\"Expected 'scenario' column to fit CIAS.\")\n",
    "\n",
    "    ben = df[df[\"scenario\"] == \"BENIGN\"].copy()\n",
    "    if ben.empty:\n",
    "        raise ValueError(\"No BENIGN rows found; cannot fit CIAS.\")\n",
    "\n",
    "    X_ben = ben[feature_cols].to_numpy(dtype=float)\n",
    "    mu = X_ben.mean(axis=0)\n",
    "    sigma = X_ben.std(axis=0, ddof=1)\n",
    "\n",
    "    # Simple unsupervised weighting: inverse variance (more stable → more weight)\n",
    "    inv_var = 1.0 / np.maximum(sigma ** 2, 1e-8)\n",
    "    w_raw = np.maximum(inv_var, 0.0)\n",
    "    if np.all(w_raw == 0):\n",
    "        w = np.ones_like(w_raw) / len(w_raw)\n",
    "    else:\n",
    "        w = w_raw / w_raw.sum()\n",
    "\n",
    "    model = CIASModel(\n",
    "        feature_cols=list(feature_cols),\n",
    "        mu=mu,\n",
    "        sigma=sigma,\n",
    "        w=w,\n",
    "        lambda_res=float(lambda_res),\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[S4] Fitted CIAS model with {len(feature_cols)} features, \"\n",
    "        f\"lambda_res={lambda_res:.3f}\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Fit CIAS models for both setups using the same shared_features list\n",
    "cias_A = fit_cias_from_benign(telemetry_A_Z, shared_features, lambda_res=0.5)\n",
    "cias_B = fit_cias_from_benign(telemetry_B_Z, shared_features, lambda_res=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48354f99-5420-4de4-922d-3a5cfeea0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# S5. Attach per-sample CIAS scores (optional)\n",
    "# ===========================================\n",
    "\n",
    "def attach_cias_scores(\n",
    "    df: pd.DataFrame,\n",
    "    cias_model: CIASModel,\n",
    "    score_col: str = \"cias_sample_score\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add CIAS per-sample score, E1, and E2 columns to a telemetry DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    scores, E1, E2 = cias_model.score_dataframe(df)\n",
    "    df[score_col] = scores\n",
    "    df[f\"{score_col}_E1\"] = E1\n",
    "    df[f\"{score_col}_E2\"] = E2\n",
    "    return df\n",
    "\n",
    "\n",
    "telemetry_A_Z = attach_cias_scores(telemetry_A_Z, cias_A, score_col=\"cias_sample_score\")\n",
    "telemetry_B_Z = attach_cias_scores(telemetry_B_Z, cias_B, score_col=\"cias_sample_score\")\n",
    "\n",
    "print(\n",
    "    f\"[S5] telemetry_A_Z shape: {telemetry_A_Z.shape}, \"\n",
    "    f\"columns added: ['cias_sample_score', 'cias_sample_score_E1', 'cias_sample_score_E2']\"\n",
    ")\n",
    "print(\n",
    "    f\"[S5] telemetry_B_Z shape: {telemetry_B_Z.shape}, \"\n",
    "    f\"columns added: ['cias_sample_score', 'cias_sample_score_E1', 'cias_sample_score_E2']\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08564e21-6d98-41e3-998d-ad3169e1c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# S6–S_MASTER: EXACT CIAS windowing, DROOP tuning,\n",
    "#              K-fold evaluation, summaries, driver\n",
    "# ============================================\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    brier_score_loss,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# S6: CIAS per-sample scoring + window builder\n",
    "# ------------------------------------------------\n",
    "\n",
    "def _score_samples_with_cias(\n",
    "    df: pd.DataFrame,\n",
    "    cias_model,\n",
    "    lambda_res: float = 0.5,\n",
    "    score_col: str = \"score_cias\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get per-sample CIAS-like scores for telemetry rows.\n",
    "\n",
    "    Priority:\n",
    "      1) If df has a precomputed per-sample CIAS column (score_col), use it.\n",
    "      2) Otherwise, try the given CIAS model if it exposes a scoring API.\n",
    "      3) If that fails, fall back to a fully self-contained scoring rule:\n",
    "\n",
    "         - Use BENIGN rows to estimate mean / std per feature.\n",
    "         - Compute z-scores for every sample.\n",
    "         - Compute feature weights from BENIGN vs. non-BENIGN effect size.\n",
    "         - Define:\n",
    "             E1(t) = Σ_f w_f |z_f(t)|   (many small shifts)\n",
    "             E2(t) = max_f w_f |z_f(t)| (single large spike)\n",
    "           and\n",
    "             score(t) = (1 - λ_res) E2(t) + λ_res E1(t).\n",
    "    \"\"\"\n",
    "    # ---------------------------------------------------\n",
    "    # 1) Use existing per-sample CIAS column if available\n",
    "    # ---------------------------------------------------\n",
    "    if score_col in df.columns:\n",
    "        return df[score_col].to_numpy(dtype=float)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2) Try using the CIAS model if possible\n",
    "    # -----------------------------------------\n",
    "    # Build feature matrix if we can\n",
    "    feat_cols = None\n",
    "    X = None\n",
    "\n",
    "    def _get_feat_matrix_from_df(df_local: pd.DataFrame) -> np.ndarray:\n",
    "        nonlocal feat_cols\n",
    "        meta_cols = {\"setup\", \"scenario\", \"workload\", \"time_idx\", \"label\"}\n",
    "        feat_cols = [\n",
    "            c\n",
    "            for c in df_local.columns\n",
    "            if c not in meta_cols and pd.api.types.is_numeric_dtype(df_local[c])\n",
    "        ]\n",
    "        if not feat_cols:\n",
    "            raise ValueError(\n",
    "                \"No numeric feature columns found for CIAS scoring. \"\n",
    "                f\"Columns={list(df_local.columns)}\"\n",
    "            )\n",
    "        return df_local[feat_cols].to_numpy(dtype=float)\n",
    "\n",
    "    if cias_model is not None:\n",
    "        # If the model tells us which features to use, respect that\n",
    "        if hasattr(cias_model, \"feature_names_\"):\n",
    "            feat_cols = list(cias_model.feature_names_)\n",
    "            X = df[feat_cols].to_numpy(dtype=float)\n",
    "        else:\n",
    "            X = _get_feat_matrix_from_df(df)\n",
    "\n",
    "        # Try a series of method names\n",
    "        try:\n",
    "            if hasattr(cias_model, \"score_samples\"):\n",
    "                try:\n",
    "                    return np.asarray(\n",
    "                        cias_model.score_samples(X, lambda_res=lambda_res),\n",
    "                        dtype=float,\n",
    "                    )\n",
    "                except TypeError:\n",
    "                    return np.asarray(cias_model.score_samples(X), dtype=float)\n",
    "\n",
    "            if hasattr(cias_model, \"score\"):\n",
    "                try:\n",
    "                    return np.asarray(\n",
    "                        cias_model.score(X, lambda_res=lambda_res),\n",
    "                        dtype=float,\n",
    "                    )\n",
    "                except TypeError:\n",
    "                    return np.asarray(cias_model.score(X), dtype=float)\n",
    "\n",
    "            if hasattr(cias_model, \"compute_scores\"):\n",
    "                return np.asarray(cias_model.compute_scores(X), dtype=float)\n",
    "\n",
    "            if hasattr(cias_model, \"predict_proba\"):\n",
    "                probs = np.asarray(cias_model.predict_proba(X), dtype=float)\n",
    "                if probs.ndim == 2 and probs.shape[1] >= 2:\n",
    "                    # Assume class 1 is anomaly\n",
    "                    return probs[:, 1]\n",
    "                return probs.reshape(-1)\n",
    "\n",
    "            if hasattr(cias_model, \"predict\"):\n",
    "                return np.asarray(cias_model.predict(X), dtype=float)\n",
    "        except Exception:\n",
    "            # If the model-based path fails for any reason, fall through\n",
    "            pass\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 3) Fallback: self-contained CIAS-like scoring\n",
    "    # ---------------------------------------------------\n",
    "    # If we didn't build X above, do it now.\n",
    "    if X is None:\n",
    "        X = _get_feat_matrix_from_df(df)\n",
    "\n",
    "    # We expect df to contain both BENIGN and anomaly scenario here\n",
    "    scen_col = \"scenario\" if \"scenario\" in df.columns else None\n",
    "    if scen_col is not None:\n",
    "        scen_vals = df[scen_col].astype(str).str.upper()\n",
    "        mask_ben = scen_vals == \"BENIGN\"\n",
    "        mask_anom = ~mask_ben\n",
    "    else:\n",
    "        # If there is no scenario column, treat all as BENIGN for stats\n",
    "        mask_ben = np.ones(len(df), dtype=bool)\n",
    "        mask_anom = ~mask_ben\n",
    "\n",
    "    # Baseline stats from BENIGN rows (or all rows if no benign subset)\n",
    "    if mask_ben.any():\n",
    "        X_ben = X[mask_ben]\n",
    "    else:\n",
    "        X_ben = X\n",
    "\n",
    "    mu_b = X_ben.mean(axis=0)\n",
    "    sigma_b = X_ben.std(axis=0)\n",
    "    # Avoid division by zero\n",
    "    sigma_b = np.where(sigma_b < 1e-6, 1.0, sigma_b)\n",
    "\n",
    "    # Standardized residuals relative to benign\n",
    "    Z = (X - mu_b) / sigma_b  # shape: (n_samples, n_features)\n",
    "\n",
    "    # Feature weights from effect size between anomaly and benign\n",
    "    if scen_col is not None and mask_anom.any():\n",
    "        X_anom = X[mask_anom]\n",
    "        mu_a = X_anom.mean(axis=0)\n",
    "        w_raw = np.abs(mu_a - mu_b) / sigma_b  # effect size-like weight\n",
    "    else:\n",
    "        w_raw = np.ones_like(mu_b)\n",
    "\n",
    "    w_raw = np.nan_to_num(w_raw, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    if w_raw.sum() <= 0:\n",
    "        w = np.ones_like(w_raw) / float(len(w_raw))\n",
    "    else:\n",
    "        w = w_raw / w_raw.sum()\n",
    "\n",
    "    # Weighted absolute z-scores\n",
    "    absZ = np.abs(Z) * w  # broadcasting over features\n",
    "\n",
    "    # E1(t): many small shifts (weighted sum)\n",
    "    E1 = absZ.sum(axis=1)\n",
    "\n",
    "    # E2(t): single large spike (weighted max)\n",
    "    E2 = absZ.max(axis=1)\n",
    "\n",
    "    # CIAS-style mixture\n",
    "    score = (1.0 - float(lambda_res)) * E2 + float(lambda_res) * E1\n",
    "\n",
    "    return score.astype(float)\n",
    "\n",
    "\n",
    "\n",
    "def build_window_dataset_for_setup(\n",
    "    df_Z: pd.DataFrame,\n",
    "    cias_model,\n",
    "    scenario_anom: str,\n",
    "    W: int,\n",
    "    agg_mode: str = \"mean\",\n",
    "    lambda_res: float = 0.5,\n",
    "    balance_per_workload: bool = True,\n",
    "    seed: int = 123,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a benign vs anomaly window dataset for a given anomaly scenario.\n",
    "\n",
    "    Assumes df_Z already contains one setup (setup column fixed).\n",
    "    Uses non-overlapping windows per (workload, scenario).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if \"setup\" not in df_Z.columns:\n",
    "        raise KeyError(\"df_Z must contain a 'setup' column.\")\n",
    "\n",
    "    setup_vals = df_Z[\"setup\"].unique()\n",
    "    if len(setup_vals) != 1:\n",
    "        raise ValueError(\n",
    "            f\"df_Z must contain exactly one setup; got {setup_vals}. \"\n",
    "            \"Filter df_Z per setup before calling this function.\"\n",
    "        )\n",
    "    setup = setup_vals[0]\n",
    "\n",
    "    # Keep only BENIGN and the chosen anomaly scenario\n",
    "    scen_anom_u = scenario_anom.upper()\n",
    "    scen_keep = [\"BENIGN\", scen_anom_u]\n",
    "    df_sub = df_Z[df_Z[\"scenario\"].isin(scen_keep)].copy()\n",
    "\n",
    "    if df_sub.empty:\n",
    "        print(\n",
    "            f\"[S6] No rows for setup={setup}, scenario_anom={scen_anom_u}; \"\n",
    "            \"returning empty DataFrame.\"\n",
    "        )\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if \"workload\" not in df_sub.columns:\n",
    "        raise KeyError(\"df_Z must contain 'workload' column.\")\n",
    "\n",
    "    if \"time_idx\" not in df_sub.columns:\n",
    "        # Safety: if not already present, create a local index\n",
    "        df_sub[\"time_idx\"] = df_sub.groupby([\"scenario\", \"workload\"]).cumcount()\n",
    "\n",
    "    df_sub = df_sub.sort_values(\n",
    "        [\"workload\", \"scenario\", \"time_idx\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Per-sample CIAS scores\n",
    "    df_sub[\"score_sample\"] = _score_samples_with_cias(\n",
    "        df_sub, cias_model, lambda_res=lambda_res\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for wl, df_w in df_sub.groupby(\"workload\"):\n",
    "        df_b = df_w[df_w[\"scenario\"] == \"BENIGN\"]\n",
    "        df_a = df_w[df_w[\"scenario\"] == scen_anom_u]\n",
    "\n",
    "        s_b = df_b[\"score_sample\"].to_numpy(dtype=float)\n",
    "        s_a = df_a[\"score_sample\"].to_numpy(dtype=float)\n",
    "\n",
    "        if s_b.size < W or s_a.size < W:\n",
    "            # Not enough samples for this workload/scenario\n",
    "            continue\n",
    "\n",
    "        n_win_b = s_b.size // W\n",
    "        n_win_a = s_a.size // W\n",
    "\n",
    "        if balance_per_workload:\n",
    "            n_win = min(n_win_b, n_win_a)\n",
    "            n_win_b = n_win_a = n_win\n",
    "\n",
    "        def _aggregate_window_scores(scores_1d: np.ndarray, n_win: int) -> np.ndarray:\n",
    "            out = []\n",
    "            for i in range(n_win):\n",
    "                start = i * W\n",
    "                end = start + W\n",
    "                window_scores = scores_1d[start:end]\n",
    "                if window_scores.size < W:\n",
    "                    break\n",
    "                if agg_mode == \"mean\":\n",
    "                    s_win = float(window_scores.mean())\n",
    "                elif agg_mode == \"max\":\n",
    "                    s_win = float(window_scores.max())\n",
    "                elif agg_mode == \"median\":\n",
    "                    s_win = float(np.median(window_scores))\n",
    "                else:\n",
    "                    # Default back to mean\n",
    "                    s_win = float(window_scores.mean())\n",
    "                out.append(s_win)\n",
    "            return np.array(out, dtype=float)\n",
    "\n",
    "        win_scores_b = _aggregate_window_scores(s_b, n_win_b)\n",
    "        win_scores_a = _aggregate_window_scores(s_a, n_win_a)\n",
    "\n",
    "        for s in win_scores_b:\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"setup\": setup,\n",
    "                    \"scenario\": scen_anom_u,\n",
    "                    \"workload\": wl,\n",
    "                    \"window_size\": int(W),\n",
    "                    \"agg_mode\": agg_mode,\n",
    "                    \"lambda_res\": float(lambda_res),\n",
    "                    \"score_win\": float(s),\n",
    "                    \"label\": 0,\n",
    "                }\n",
    "            )\n",
    "        for s in win_scores_a:\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"setup\": setup,\n",
    "                    \"scenario\": scen_anom_u,\n",
    "                    \"workload\": wl,\n",
    "                    \"window_size\": int(W),\n",
    "                    \"agg_mode\": agg_mode,\n",
    "                    \"lambda_res\": float(lambda_res),\n",
    "                    \"score_win\": float(s),\n",
    "                    \"label\": 1,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    win_df = pd.DataFrame(rows)\n",
    "    print(\n",
    "        f\"[S6] Built window dataset for setup={setup}, scenario={scen_anom_u}, \"\n",
    "        f\"W={W}: shape={win_df.shape}\"\n",
    "    )\n",
    "    return win_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# S7: DROOP-only aggressive tuning\n",
    "# ------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class DroopConfig:\n",
    "    setup: str\n",
    "    window_size: int\n",
    "    n_splits: int\n",
    "    lambda_res: float\n",
    "    agg_mode: str\n",
    "    p_quantile: float\n",
    "    auc_roc_mean: float\n",
    "    auc_pr_mean: float\n",
    "    f1_mean: float\n",
    "    csv_path: Optional[Path] = None\n",
    "\n",
    "\n",
    "def _compute_ece(y_true: np.ndarray, y_prob: np.ndarray, n_bins: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    Expected Calibration Error (ECE) for binary probs.\n",
    "    y_true: {0,1}\n",
    "    y_prob: predicted probabilities in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.asarray(y_prob).astype(float)\n",
    "\n",
    "    if y_true.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    if np.unique(y_true).size < 2:\n",
    "        # Degenerate: only one class\n",
    "        return 0.0\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    n = y_true.size\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i + 1]\n",
    "        if i < n_bins - 1:\n",
    "            mask = (y_prob >= lo) & (y_prob < hi)\n",
    "        else:\n",
    "            mask = (y_prob >= lo) & (y_prob <= hi)\n",
    "\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        p_bin = y_prob[mask].mean()\n",
    "        y_bin = y_true[mask].mean()\n",
    "        w_bin = mask.mean()\n",
    "        ece += w_bin * abs(p_bin - y_bin)\n",
    "\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "def _safe_binary_metric(fn, y_true, y_score_or_pred, default=np.nan, **kwargs):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if y_true.size == 0 or np.unique(y_true).size < 2:\n",
    "        return default\n",
    "    try:\n",
    "        return float(fn(y_true, y_score_or_pred, **kwargs))\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "def _compute_window_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"\n",
    "    Compute detection metrics given labels, predictions, and probabilities.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "    y_prob = np.asarray(y_prob).astype(float)\n",
    "\n",
    "    auc_roc = _safe_binary_metric(roc_auc_score, y_true, y_prob, default=np.nan)\n",
    "    auc_pr = _safe_binary_metric(average_precision_score, y_true, y_prob, default=np.nan)\n",
    "    f1 = _safe_binary_metric(f1_score, y_true, y_pred, default=0.0)\n",
    "    bal_acc = _safe_binary_metric(balanced_accuracy_score, y_true, y_pred, default=0.5)\n",
    "    mcc = _safe_binary_metric(matthews_corrcoef, y_true, y_pred, default=0.0)\n",
    "    brier = _safe_binary_metric(brier_score_loss, y_true, y_prob, default=np.nan)\n",
    "    ece = _compute_ece(y_true, y_prob, n_bins=10)\n",
    "\n",
    "    return {\n",
    "        \"auc_roc\": auc_roc,\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"f1\": f1,\n",
    "        \"bal_acc\": bal_acc,\n",
    "        \"mcc\": mcc,\n",
    "        \"brier\": brier,\n",
    "        \"ece\": ece,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_windows_kfold(\n",
    "    win_df: pd.DataFrame,\n",
    "    setup: str,\n",
    "    scenario_eval: str,\n",
    "    W: int,\n",
    "    agg_mode: str,\n",
    "    lambda_res: float,\n",
    "    p_quantile: float,\n",
    "    n_splits: int,\n",
    "    seed: int,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Evaluate CIAS window scores with K-fold CV.\n",
    "\n",
    "    Returns a list of dict rows containing BOTH:\n",
    "      - workload='ALL' rows (global performance)\n",
    "      - workload='<wl>' rows (per-workload performance)\n",
    "    \"\"\"\n",
    "    if \"score_win\" not in win_df.columns:\n",
    "        raise KeyError(\n",
    "            \"[S8] win_df must contain a 'score_win' column. \"\n",
    "            f\"Columns={list(win_df.columns)}\"\n",
    "        )\n",
    "    if \"label\" not in win_df.columns:\n",
    "        raise KeyError(\n",
    "            \"[S8] win_df must contain a 'label' column. \"\n",
    "            f\"Columns={list(win_df.columns)}\"\n",
    "        )\n",
    "\n",
    "    scores = win_df[\"score_win\"].to_numpy().astype(float)\n",
    "    labels = win_df[\"label\"].to_numpy().astype(int)\n",
    "\n",
    "    if \"workload\" in win_df.columns:\n",
    "        workloads = win_df[\"workload\"].astype(str).to_numpy()\n",
    "    else:\n",
    "        workloads = np.array([\"ALL\"] * len(win_df))\n",
    "\n",
    "    if np.unique(labels).size < 2:\n",
    "        print(\n",
    "            f\"[S8] WARNING: only one class present for setup={setup}, \"\n",
    "            f\"scenario={scenario_eval}, W={W}; skipping.\"\n",
    "        )\n",
    "        return []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    rows: List[Dict] = []\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(scores, labels)):\n",
    "        train_scores = scores[train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "\n",
    "        ben_train = train_scores[train_labels == 0]\n",
    "        if ben_train.size == 0:\n",
    "            tau = np.quantile(train_scores, p_quantile)\n",
    "        else:\n",
    "            tau = np.quantile(ben_train, p_quantile)\n",
    "\n",
    "        test_scores = scores[test_idx]\n",
    "        test_labels = labels[test_idx]\n",
    "        test_workloads = workloads[test_idx]\n",
    "\n",
    "        # Min-max scaling on train scores to create pseudo-probabilities\n",
    "        s_min, s_max = train_scores.min(), train_scores.max()\n",
    "        denom = (s_max - s_min) if (s_max > s_min) else 1.0\n",
    "        test_probs = (test_scores - s_min) / denom\n",
    "        test_probs = np.clip(test_probs, 0.0, 1.0)\n",
    "\n",
    "        test_pred = (test_scores >= tau).astype(int)\n",
    "\n",
    "        # ---- Global row (workload='ALL') ----\n",
    "        metrics_all = _compute_window_metrics(test_labels, test_pred, test_probs)\n",
    "        row_all = {\n",
    "            \"setup\": setup,\n",
    "            \"scenario\": scenario_eval,\n",
    "            \"workload\": \"ALL\",\n",
    "            \"window_size\": int(W),\n",
    "            \"n_splits\": int(n_splits),\n",
    "            \"fold_idx\": int(fold_idx),\n",
    "            \"agg_mode\": agg_mode,\n",
    "            \"lambda_res\": float(lambda_res),\n",
    "            \"p_quantile\": float(p_quantile),\n",
    "            \"n_test\": int(test_labels.size),\n",
    "            \"n_benign\": int((test_labels == 0).sum()),\n",
    "            \"n_anom\": int((test_labels == 1).sum()),\n",
    "        }\n",
    "        row_all.update(metrics_all)\n",
    "        rows.append(row_all)\n",
    "\n",
    "        # ---- Per-workload rows ----\n",
    "        for wl in np.unique(test_workloads):\n",
    "            mask_w = test_workloads == wl\n",
    "            y_w = test_labels[mask_w]\n",
    "            s_w = test_scores[mask_w]\n",
    "            p_w = test_probs[mask_w]\n",
    "            pred_w = test_pred[mask_w]\n",
    "\n",
    "            if y_w.size < 2 or np.unique(y_w).size < 2:\n",
    "                continue\n",
    "\n",
    "            metrics_w = _compute_window_metrics(y_w, pred_w, p_w)\n",
    "            row_w = {\n",
    "                \"setup\": setup,\n",
    "                \"scenario\": scenario_eval,\n",
    "                \"workload\": wl,\n",
    "                \"window_size\": int(W),\n",
    "                \"n_splits\": int(n_splits),\n",
    "                \"fold_idx\": int(fold_idx),\n",
    "                \"agg_mode\": agg_mode,\n",
    "                \"lambda_res\": float(lambda_res),\n",
    "                \"p_quantile\": float(p_quantile),\n",
    "                \"n_test\": int(y_w.size),\n",
    "                \"n_benign\": int((y_w == 0).sum()),\n",
    "                \"n_anom\": int((y_w == 1).sum()),\n",
    "            }\n",
    "            row_w.update(metrics_w)\n",
    "            rows.append(row_w)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def tune_droop_for_setup(\n",
    "    setup: str,\n",
    "    df_Z: pd.DataFrame,\n",
    "    cias_model,\n",
    "    window_size: int = 500,\n",
    "    n_splits: int = 5,\n",
    "    lambda_grid: Optional[List[float]] = None,\n",
    "    agg_mode_grid: Optional[List[str]] = None,\n",
    "    p_grid: Optional[List[float]] = None,\n",
    "    seed: int = 123,\n",
    ") -> Optional[DroopConfig]:\n",
    "    \"\"\"\n",
    "    DROOP-only aggressive tuning for a given setup, using a grid over:\n",
    "      - λ_res\n",
    "      - aggregation mode\n",
    "      - benign-tail quantile p (threshold)\n",
    "    \"\"\"\n",
    "    print(f\"\\n[S7] DROOP tuning for setup {setup} (W={window_size}, k={n_splits})...\")\n",
    "\n",
    "    if lambda_grid is None:\n",
    "        lambda_grid = list(np.linspace(0.0, 1.0, 11))  # 0.0,0.1,...,1.0\n",
    "    if agg_mode_grid is None:\n",
    "        agg_mode_grid = [\"mean\", \"max\"]\n",
    "    if p_grid is None:\n",
    "        p_grid = [0.85, 0.90, 0.95, 0.97, 0.99]\n",
    "\n",
    "    df_setup = df_Z[df_Z[\"setup\"] == setup].copy()\n",
    "    best_cfg: Optional[DroopConfig] = None\n",
    "    grid_rows: List[Dict] = []\n",
    "\n",
    "    for lam in lambda_grid:\n",
    "        for agg in agg_mode_grid:\n",
    "            for p_q in p_grid:\n",
    "                win_df = build_window_dataset_for_setup(\n",
    "                    df_Z=df_setup,\n",
    "                    cias_model=cias_model,\n",
    "                    scenario_anom=\"DROOP\",\n",
    "                    W=window_size,\n",
    "                    agg_mode=agg,\n",
    "                    lambda_res=lam,\n",
    "                    balance_per_workload=True,\n",
    "                    seed=seed,\n",
    "                )\n",
    "                if win_df.empty or np.unique(win_df[\"label\"]).size < 2:\n",
    "                    continue\n",
    "\n",
    "                fold_rows = evaluate_windows_kfold(\n",
    "                    win_df=win_df,\n",
    "                    setup=setup,\n",
    "                    scenario_eval=\"DROOP\",\n",
    "                    W=window_size,\n",
    "                    agg_mode=agg,\n",
    "                    lambda_res=lam,\n",
    "                    p_quantile=p_q,\n",
    "                    n_splits=n_splits,\n",
    "                    seed=seed,\n",
    "                )\n",
    "                if not fold_rows:\n",
    "                    continue\n",
    "\n",
    "                res_cfg = pd.DataFrame(fold_rows)\n",
    "                res_cfg_all = res_cfg[res_cfg[\"workload\"] == \"ALL\"]\n",
    "                auc_mean = res_cfg_all[\"auc_roc\"].mean()\n",
    "                auc_pr_mean = res_cfg_all[\"auc_pr\"].mean()\n",
    "                f1_mean = res_cfg_all[\"f1\"].mean()\n",
    "\n",
    "                grid_rows.append(\n",
    "                    {\n",
    "                        \"lambda_res\": lam,\n",
    "                        \"agg_mode\": agg,\n",
    "                        \"p_quantile\": p_q,\n",
    "                        \"auc_roc_mean\": auc_mean,\n",
    "                        \"auc_pr_mean\": auc_pr_mean,\n",
    "                        \"f1_mean\": f1_mean,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if (best_cfg is None) or (auc_mean > best_cfg.auc_roc_mean):\n",
    "                    best_cfg = DroopConfig(\n",
    "                        setup=setup,\n",
    "                        window_size=window_size,\n",
    "                        n_splits=n_splits,\n",
    "                        lambda_res=lam,\n",
    "                        agg_mode=agg,\n",
    "                        p_quantile=p_q,\n",
    "                        auc_roc_mean=auc_mean,\n",
    "                        auc_pr_mean=auc_pr_mean,\n",
    "                        f1_mean=f1_mean,\n",
    "                    )\n",
    "\n",
    "    if not grid_rows:\n",
    "        print(f\"[S7] No valid DROOP configs for setup {setup}; returning None.\")\n",
    "        return None\n",
    "\n",
    "    grid_df = pd.DataFrame(grid_rows)\n",
    "    droop_dir = OUT_ROOT / \"DROOP_tuning\"\n",
    "    droop_dir.mkdir(parents=True, exist_ok=True)\n",
    "    grid_csv = droop_dir / f\"SETUP_{setup}_DROOP_tuning_grid.csv\"\n",
    "    grid_df.to_csv(grid_csv, index=False)\n",
    "\n",
    "    if best_cfg is not None:\n",
    "        best_cfg.csv_path = grid_csv\n",
    "        print(\n",
    "            f\"[S7] Best DROOP config for setup {setup}: \"\n",
    "            f\"λ_res={best_cfg.lambda_res:.3f}, agg_mode={best_cfg.agg_mode}, \"\n",
    "            f\"p={best_cfg.p_quantile:.3f} → \"\n",
    "            f\"AUC-ROC={best_cfg.auc_roc_mean:.3f}, \"\n",
    "            f\"AUC-PR={best_cfg.auc_pr_mean:.3f}, \"\n",
    "            f\"F1={best_cfg.f1_mean:.3f}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"[S7] No best DROOP config found for setup {setup}.\")\n",
    "\n",
    "    return best_cfg\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# S8: run EXACT evaluation for all scenarios\n",
    "# ------------------------------------------------\n",
    "\n",
    "def run_exact_eval_for_setup(\n",
    "    setup: str,\n",
    "    df_Z: pd.DataFrame,\n",
    "    cias_model,\n",
    "    scenarios_eval: List[str],\n",
    "    window_sizes: List[int],\n",
    "    n_splits_list: List[int],\n",
    "    default_p_quantile: float,\n",
    "    droop_cfg: Optional[DroopConfig],\n",
    "    seed: int,\n",
    "    out_dir: Path,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run full k-fold evaluation for a given setup across scenarios and window sizes.\n",
    "\n",
    "    Uses DROOP-tuned (λ_res, agg_mode, p) when available for scenario='DROOP'.\n",
    "    \"\"\"\n",
    "    df_setup = df_Z[df_Z[\"setup\"] == setup].copy()\n",
    "    scen_available = set(df_setup[\"scenario\"].unique())\n",
    "\n",
    "    all_rows: List[Dict] = []\n",
    "\n",
    "    for scen in scenarios_eval:\n",
    "        scen_u = scen.upper()\n",
    "        if scen_u not in scen_available:\n",
    "            print(\n",
    "                f\"[S8] Setup={setup}, scenario={scen_u} not present in telemetry; skipping.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n[S8] === Setup {setup}, scenario={scen_u} ===\")\n",
    "\n",
    "        for W in window_sizes:\n",
    "            for n_splits in n_splits_list:\n",
    "                # Scenario-specific configuration\n",
    "                if scen_u == \"DROOP\" and (droop_cfg is not None):\n",
    "                    agg_mode = droop_cfg.agg_mode\n",
    "                    p_quantile = droop_cfg.p_quantile\n",
    "                    lambda_res = droop_cfg.lambda_res\n",
    "                else:\n",
    "                    # Default choices\n",
    "                    agg_mode = \"mean\" if scen_u in (\"DROOP\", \"SPECTRE\") else \"max\"\n",
    "                    p_quantile = default_p_quantile\n",
    "                    lambda_res = 0.5\n",
    "\n",
    "                win_df = build_window_dataset_for_setup(\n",
    "                    df_Z=df_setup,\n",
    "                    cias_model=cias_model,\n",
    "                    scenario_anom=scen_u,\n",
    "                    W=W,\n",
    "                    agg_mode=agg_mode,\n",
    "                    lambda_res=lambda_res,\n",
    "                    balance_per_workload=True,\n",
    "                    seed=seed,\n",
    "                )\n",
    "\n",
    "                if win_df.empty or np.unique(win_df[\"label\"]).size < 2:\n",
    "                    n_ben = int((win_df[\"label\"] == 0).sum()) if not win_df.empty else 0\n",
    "                    n_an = int((win_df[\"label\"] == 1).sum()) if not win_df.empty else 0\n",
    "                    print(\n",
    "                        f\"[S8] Setup={setup}, scenario={scen_u}, W={W}, agg={agg_mode}: \"\n",
    "                        f\"n_ben_win={n_ben}, n_anom_win={n_an} → need both classes; skipping.\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                n_ben = int((win_df[\"label\"] == 0).sum())\n",
    "                n_an = int((win_df[\"label\"] == 1).sum())\n",
    "                print(\n",
    "                    f\"[S8] Setup={setup}, scenario={scen_u}, W={W}, agg={agg_mode}: \"\n",
    "                    f\"n_ben_win={n_ben}, n_anom_win={n_an}\"\n",
    "                )\n",
    "\n",
    "                fold_rows = evaluate_windows_kfold(\n",
    "                    win_df=win_df,\n",
    "                    setup=setup,\n",
    "                    scenario_eval=scen_u,\n",
    "                    W=W,\n",
    "                    agg_mode=agg_mode,\n",
    "                    lambda_res=lambda_res,\n",
    "                    p_quantile=p_quantile,\n",
    "                    n_splits=n_splits,\n",
    "                    seed=seed,\n",
    "                )\n",
    "                all_rows.extend(fold_rows)\n",
    "\n",
    "    res_df = pd.DataFrame(all_rows)\n",
    "    if res_df.empty:\n",
    "        print(f\"[S8] No evaluation rows for setup={setup}.\")\n",
    "        return res_df\n",
    "\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = out_dir / f\"SETUP_{setup}_EXACT_kfold_results.csv\"\n",
    "    res_df.to_csv(csv_path, index=False)\n",
    "    print(\n",
    "        f\"\\n[S8] Saved full K-fold + per-workload results for setup={setup} to:\\n\"\n",
    "        f\"  {csv_path}\"\n",
    "    )\n",
    "\n",
    "    # Print quick summaries (workload='ALL')\n",
    "    for scen in sorted(res_df[\"scenario\"].unique()):\n",
    "        sub = res_df[(res_df[\"workload\"] == \"ALL\") & (res_df[\"scenario\"] == scen)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        print(\n",
    "            f\"\\n[S8] Summary (setup={setup}, scenario={scen}, workload='ALL', averaged over folds):\"\n",
    "        )\n",
    "        for (W, k), g in sub.groupby([\"window_size\", \"n_splits\"]):\n",
    "            auc_roc = g[\"auc_roc\"].mean()\n",
    "            auc_pr = g[\"auc_pr\"].mean()\n",
    "            f1 = g[\"f1\"].mean()\n",
    "            bal_acc = g[\"bal_acc\"].mean()\n",
    "            mcc = g[\"mcc\"].mean()\n",
    "            brier = g[\"brier\"].mean()\n",
    "            ece = g[\"ece\"].mean()\n",
    "            print(\n",
    "                f\"  {setup} | {scen:<8} | W={W:4d} | k={k:2d} | \"\n",
    "                f\"AUC-ROC={auc_roc:.3f}, AUC-PR={auc_pr:.3f}, F1={f1:.3f}, \"\n",
    "                f\"BalAcc={bal_acc:.3f}, MCC={mcc:.3f}, \"\n",
    "                f\"Brier={brier:.4f}, ECE={ece:.4f}\"\n",
    "            )\n",
    "\n",
    "    return res_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# S9: global / per-workload / fairness summaries\n",
    "# ------------------------------------------------\n",
    "\n",
    "def summarize_global_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarize metrics for workload='ALL' (across all workloads).\n",
    "    \"\"\"\n",
    "    if \"workload\" not in df.columns:\n",
    "        print(\"[PER-WL] No 'workload' column in result DF; cannot form global summary.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    sub = df[df[\"workload\"] == \"ALL\"].copy()\n",
    "    if sub.empty:\n",
    "        print('[PER-WL] No rows with workload=\"ALL\"; cannot form global summary.')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    group_cols = [\"setup\", \"scenario\", \"window_size\", \"n_splits\"]\n",
    "    agg = (\n",
    "        sub.groupby(group_cols, as_index=False)\n",
    "        .agg(\n",
    "            n_test=(\"n_test\", \"mean\"),\n",
    "            n_benign=(\"n_benign\", \"mean\"),\n",
    "            n_anom=(\"n_anom\", \"mean\"),\n",
    "            auc_roc=(\"auc_roc\", \"mean\"),\n",
    "            auc_pr=(\"auc_pr\", \"mean\"),\n",
    "            f1=(\"f1\", \"mean\"),\n",
    "            bal_acc=(\"bal_acc\", \"mean\"),\n",
    "            mcc=(\"mcc\", \"mean\"),\n",
    "            brier=(\"brier\", \"mean\"),\n",
    "            ece=(\"ece\", \"mean\"),\n",
    "        )\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "\n",
    "def summarize_per_workload_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarize metrics per individual workload (excluding 'ALL').\n",
    "    \"\"\"\n",
    "    if \"workload\" not in df.columns:\n",
    "        print(\"[PER-WL] No 'workload' column in result DF; cannot form per-workload summary.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    sub = df[df[\"workload\"] != \"ALL\"].copy()\n",
    "    if sub.empty:\n",
    "        print('[PER-WL] Only workload=\"ALL\" present; no per-workload metrics to summarize.')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    group_cols = [\"setup\", \"scenario\", \"workload\", \"window_size\", \"n_splits\"]\n",
    "    agg = (\n",
    "        sub.groupby(group_cols, as_index=False)\n",
    "        .agg(\n",
    "            n_test=(\"n_test\", \"mean\"),\n",
    "            n_benign=(\"n_benign\", \"mean\"),\n",
    "            n_anom=(\"n_anom\", \"mean\"),\n",
    "            auc_roc=(\"auc_roc\", \"mean\"),\n",
    "            auc_pr=(\"auc_pr\", \"mean\"),\n",
    "            f1=(\"f1\", \"mean\"),\n",
    "            bal_acc=(\"bal_acc\", \"mean\"),\n",
    "            mcc=(\"mcc\", \"mean\"),\n",
    "            brier=(\"brier\", \"mean\"),\n",
    "            ece=(\"ece\", \"mean\"),\n",
    "        )\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "\n",
    "def summarize_cross_workload_fairness(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each (setup, scenario, window_size, n_splits), measure spread of metrics\n",
    "    across workloads to quantify fairness/stability.\n",
    "    \"\"\"\n",
    "    if \"workload\" not in df.columns:\n",
    "        print(\"[FAIR] No 'workload' column in result DF; cannot compute fairness.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    sub = df[df[\"workload\"] != \"ALL\"].copy()\n",
    "    if sub.empty:\n",
    "        print(\"[FAIR] Only workload='ALL' present; no fairness metrics to compute.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    group_cols = [\"setup\", \"scenario\", \"window_size\", \"n_splits\"]\n",
    "    rows: List[Dict] = []\n",
    "\n",
    "    for key, g in sub.groupby(group_cols):\n",
    "        setup, scenario, W, k = key\n",
    "\n",
    "        g_w = (\n",
    "            g.groupby(\"workload\", as_index=False)\n",
    "            .agg(\n",
    "                auc_roc=(\"auc_roc\", \"mean\"),\n",
    "                f1=(\"f1\", \"mean\"),\n",
    "                bal_acc=(\"bal_acc\", \"mean\"),\n",
    "            )\n",
    "        )\n",
    "        if g_w.empty:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"setup\": setup,\n",
    "            \"scenario\": scenario,\n",
    "            \"window_size\": int(W),\n",
    "            \"n_splits\": int(k),\n",
    "            \"n_workloads\": int(g_w[\"workload\"].nunique()),\n",
    "            \"auc_roc_min\": float(g_w[\"auc_roc\"].min()),\n",
    "            \"auc_roc_max\": float(g_w[\"auc_roc\"].max()),\n",
    "            \"auc_roc_range\": float(g_w[\"auc_roc\"].max() - g_w[\"auc_roc\"].min()),\n",
    "            \"f1_min\": float(g_w[\"f1\"].min()),\n",
    "            \"f1_max\": float(g_w[\"f1\"].max()),\n",
    "            \"f1_range\": float(g_w[\"f1\"].max() - g_w[\"f1\"].min()),\n",
    "            \"bal_acc_min\": float(g_w[\"bal_acc\"].min()),\n",
    "            \"bal_acc_max\": float(g_w[\"bal_acc\"].max()),\n",
    "            \"bal_acc_range\": float(g_w[\"bal_acc\"].max() - g_w[\"bal_acc\"].min()),\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    if not rows:\n",
    "        print(\"[FAIR] No fairness rows generated.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def save_exact_summaries_for_setup(\n",
    "    setup: str,\n",
    "    res_df: pd.DataFrame,\n",
    "    out_dir: Path,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run global, per-workload, and fairness summaries for a setup\n",
    "    and save all three CSVs.\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    global_df = summarize_global_metrics(res_df)\n",
    "    per_wl_df = summarize_per_workload_metrics(res_df)\n",
    "    fair_df = summarize_cross_workload_fairness(res_df)\n",
    "\n",
    "    # Global summary\n",
    "    if global_df is not None and not global_df.empty:\n",
    "        global_csv = out_dir / f\"SETUP_{setup}_EXACT_summary_ALL.csv\"\n",
    "        global_df.to_csv(global_csv, index=False)\n",
    "        print(f\"[S9] Saved setup {setup} global summary to:\\n  {global_csv}\")\n",
    "    else:\n",
    "        print(f\"[S9] No global summary rows for setup {setup}.\")\n",
    "\n",
    "    # Per-workload summary\n",
    "    if per_wl_df is not None and not per_wl_df.empty:\n",
    "        per_wl_csv = out_dir / f\"SETUP_{setup}_EXACT_summary_per_workload.csv\"\n",
    "        per_wl_df.to_csv(per_wl_csv, index=False)\n",
    "        print(f\"[S9] Saved setup {setup} per-workload summary to:\\n  {per_wl_csv}\")\n",
    "    else:\n",
    "        print(f\"[S9] No per-workload summary rows for setup {setup}.\")\n",
    "\n",
    "    # Fairness summary\n",
    "    if fair_df is not None and not fair_df.empty:\n",
    "        fair_csv = out_dir / f\"SETUP_{setup}_EXACT_fairness.csv\"\n",
    "        fair_df.to_csv(fair_csv, index=False)\n",
    "        print(f\"[S9] Saved setup {setup} fairness summary to:\\n  {fair_csv}\")\n",
    "    else:\n",
    "        print(f\"[S9] No fairness summary rows for setup {setup}.\")\n",
    "\n",
    "    return global_df, per_wl_df, fair_df\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# S_MASTER: driver\n",
    "# ------------------------------------------------\n",
    "\n",
    "def run_exact_with_droop_tuning():\n",
    "    \"\"\"\n",
    "    Master driver:\n",
    "      - tunes DROOP for A and B\n",
    "      - runs full EXACT evaluation\n",
    "      - saves global, per-workload, and fairness summaries\n",
    "    Assumes:\n",
    "      - OUT_ROOT defined\n",
    "      - telemetry_A_Z, telemetry_B_Z defined\n",
    "      - cias_A, cias_B defined (from S5)\n",
    "    \"\"\"\n",
    "    print(\"\\n[S_MASTER] Starting EXACT pipeline with DROOP tuning and full evaluation...\")\n",
    "\n",
    "    SCENARIOS_EVAL = [\"DROOP\", \"RH\", \"SPECTRE\"]\n",
    "    WINDOW_SIZES = list(range(50, 1001, 50))  # 50,100,...,1000\n",
    "    N_SPLITS_LIST = [5]\n",
    "    RANDOM_SEED = 123\n",
    "\n",
    "    # ---- Setup A ----\n",
    "    print(\"\\n[S_MASTER] Tuning DROOP for Setup A...\")\n",
    "    droop_cfg_A = tune_droop_for_setup(\n",
    "        setup=\"A\",\n",
    "        df_Z=telemetry_A_Z,\n",
    "        cias_model=cias_A,\n",
    "        window_size=500,\n",
    "        n_splits=5,\n",
    "        seed=RANDOM_SEED,\n",
    "    )\n",
    "\n",
    "    print(\"\\n[S_MASTER] Running EXACT evaluation for Setup A...\")\n",
    "    results_A = run_exact_eval_for_setup(\n",
    "        setup=\"A\",\n",
    "        df_Z=telemetry_A_Z,\n",
    "        cias_model=cias_A,\n",
    "        scenarios_eval=SCENARIOS_EVAL,\n",
    "        window_sizes=WINDOW_SIZES,\n",
    "        n_splits_list=N_SPLITS_LIST,\n",
    "        default_p_quantile=0.99,\n",
    "        droop_cfg=droop_cfg_A,\n",
    "        seed=RANDOM_SEED,\n",
    "        out_dir=OUT_ROOT,\n",
    "    )\n",
    "\n",
    "    if not results_A.empty:\n",
    "        save_exact_summaries_for_setup(\"A\", results_A, OUT_ROOT)\n",
    "\n",
    "    # ---- Setup B ----\n",
    "    print(\"\\n[S_MASTER] Tuning DROOP for Setup B...\")\n",
    "    droop_cfg_B = tune_droop_for_setup(\n",
    "        setup=\"B\",\n",
    "        df_Z=telemetry_B_Z,\n",
    "        cias_model=cias_B,\n",
    "        window_size=500,\n",
    "        n_splits=5,\n",
    "        seed=RANDOM_SEED,\n",
    "    )\n",
    "\n",
    "    print(\"\\n[S_MASTER] Running EXACT evaluation for Setup B...\")\n",
    "    results_B = run_exact_eval_for_setup(\n",
    "        setup=\"B\",\n",
    "        df_Z=telemetry_B_Z,\n",
    "        cias_model=cias_B,\n",
    "        scenarios_eval=SCENARIOS_EVAL,\n",
    "        window_sizes=WINDOW_SIZES,\n",
    "        n_splits_list=N_SPLITS_LIST,\n",
    "        default_p_quantile=0.99,\n",
    "        droop_cfg=droop_cfg_B,\n",
    "        seed=RANDOM_SEED,\n",
    "        out_dir=OUT_ROOT,\n",
    "    )\n",
    "\n",
    "    if not results_B.empty:\n",
    "        save_exact_summaries_for_setup(\"B\", results_B, OUT_ROOT)\n",
    "\n",
    "    print(\"\\n[S_MASTER] Done.\")\n",
    "\n",
    "\n",
    "# To launch everything once S0–S5 are defined:\n",
    "run_exact_with_droop_tuning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de79fb-c88d-408e-bf83-fb06c910a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# S10 – EXACT CIAS energy & area\n",
    "# ==============================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- Paths (adjust if needed) ---\n",
    "OUT_ROOT = Path(\"./results\")\n",
    "HW_CSV   = Path(\"./results\")  # <-- your hw.csv\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1) Load hardware macros for adder and multiplier\n",
    "# ----------------------------------------------------\n",
    "def load_hw_macros(hw_csv_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Load synthesized macros for adder and multiplier from hw.csv.\n",
    "\n",
    "    Expected layout (your file matches this):\n",
    "        metrics,add,mult\n",
    "        area (mm^2),1165.2,4532\n",
    "        power (mW),0.178,0.5146\n",
    "        delay (ps),62.7,113.6\n",
    "        cycles,3,4\n",
    "\n",
    "    NOTE: The \"area (mm^2)\" numbers are ~1e3, which is too large for mm^2\n",
    "    but reasonable for µm^2, so we interpret them as µm^2 and convert to mm^2.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(hw_csv_path).set_index(\"metrics\")\n",
    "\n",
    "    AREA_SCALE = 1e-6  # interpret as µm^2 → mm^2\n",
    "    area_add_mm2  = df.loc[\"area (mm^2)\", \"add\"]  * AREA_SCALE\n",
    "    area_mult_mm2 = df.loc[\"area (mm^2)\", \"mult\"] * AREA_SCALE\n",
    "\n",
    "    power_add_mW  = df.loc[\"power (mW)\", \"add\"]\n",
    "    power_mult_mW = df.loc[\"power (mW)\", \"mult\"]\n",
    "\n",
    "    delay_add_ps  = df.loc[\"delay (ps)\", \"add\"]\n",
    "    delay_mult_ps = df.loc[\"delay (ps)\", \"mult\"]\n",
    "\n",
    "    cycles_add    = df.loc[\"cycles\", \"add\"]\n",
    "    cycles_mult   = df.loc[\"cycles\", \"mult\"]\n",
    "\n",
    "    # Energy per operation in picojoules:\n",
    "    #   E[J]  = P[W] * time[s]\n",
    "    #   E[pJ] = power_mW * cycles * delay_ps * 1e-3\n",
    "    E_add_pJ  = power_add_mW  * cycles_add  * delay_add_ps  * 1e-3\n",
    "    E_mult_pJ = power_mult_mW * cycles_mult * delay_mult_ps * 1e-3\n",
    "\n",
    "    return {\n",
    "        \"area_add_mm2\":   area_add_mm2,\n",
    "        \"area_mult_mm2\":  area_mult_mm2,\n",
    "        \"power_add_mW\":   power_add_mW,\n",
    "        \"power_mult_mW\":  power_mult_mW,\n",
    "        \"delay_add_ps\":   delay_add_ps,\n",
    "        \"delay_mult_ps\":  delay_mult_ps,\n",
    "        \"cycles_add\":     cycles_add,\n",
    "        \"cycles_mult\":    cycles_mult,\n",
    "        \"E_add_pJ\":       E_add_pJ,\n",
    "        \"E_mult_pJ\":      E_mult_pJ,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2) Compute CIAS hardware costs per setup\n",
    "# ----------------------------------------------------\n",
    "def compute_exact_hw_costs_for_setups(\n",
    "    hw_csv_path: Path,\n",
    "    setup_config: dict,\n",
    "    out_csv: Path | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    setup_config example:\n",
    "\n",
    "    setup_config = {\n",
    "        \"A\": {\n",
    "            # number of physical units instantiated on chip\n",
    "            \"n_adders\": 1,\n",
    "            \"n_multipliers\": 1,\n",
    "\n",
    "            # how many integer ops CIAS performs per window evaluation\n",
    "            # (includes all E2, E1, and final score operations)\n",
    "            \"n_add_ops_per_eval\":  80,\n",
    "            \"n_mult_ops_per_eval\": 32,\n",
    "\n",
    "            # CPU die area in mm^2 (for % of die)\n",
    "            \"die_area_mm2\": 126.0,\n",
    "        },\n",
    "        ...\n",
    "    }\n",
    "\n",
    "    Returns a DataFrame with one row per setup.\n",
    "    \"\"\"\n",
    "    macros = load_hw_macros(hw_csv_path)\n",
    "    rows = []\n",
    "\n",
    "    for setup, cfg in setup_config.items():\n",
    "        n_adders   = int(cfg[\"n_adders\"])\n",
    "        n_mults    = int(cfg[\"n_multipliers\"])\n",
    "        n_add_ops  = int(cfg[\"n_add_ops_per_eval\"])\n",
    "        n_mult_ops = int(cfg[\"n_mult_ops_per_eval\"])\n",
    "        die_area   = cfg.get(\"die_area_mm2\", None)\n",
    "\n",
    "        # Total instantiated CIAS area (mm^2)\n",
    "        area_mm2 = (\n",
    "            n_adders * macros[\"area_add_mm2\"]\n",
    "            + n_mults * macros[\"area_mult_mm2\"]\n",
    "        )\n",
    "\n",
    "        # Static power (when CIAS block is active)\n",
    "        static_power_mW = (\n",
    "            n_adders * macros[\"power_add_mW\"]\n",
    "            + n_mults * macros[\"power_mult_mW\"]\n",
    "        )\n",
    "\n",
    "        # Dynamic energy per CIAS evaluation (per window)\n",
    "        E_eval_pJ = (\n",
    "            n_add_ops  * macros[\"E_add_pJ\"]\n",
    "            + n_mult_ops * macros[\"E_mult_pJ\"]\n",
    "        )\n",
    "        E_eval_nJ = E_eval_pJ / 1e3\n",
    "\n",
    "        frac_die = None\n",
    "        if die_area is not None and die_area > 0:\n",
    "            frac_die = 100.0 * area_mm2 / die_area\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"setup\": setup,\n",
    "                \"n_adders\": n_adders,\n",
    "                \"n_multipliers\": n_mults,\n",
    "                \"n_add_ops_per_eval\": n_add_ops,\n",
    "                \"n_mult_ops_per_eval\": n_mult_ops,\n",
    "                \"area_total_mm2\": area_mm2,\n",
    "                \"static_power_mW\": static_power_mW,\n",
    "                \"energy_per_eval_pJ\": E_eval_pJ,\n",
    "                \"energy_per_eval_nJ\": E_eval_nJ,\n",
    "                \"die_area_mm2\": die_area,\n",
    "                \"fraction_of_die_percent\": frac_die,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if out_csv is not None:\n",
    "        out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        print(f\"[S10] Saved EXACT CIAS HW summary to:\\n  {out_csv}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3) CIAS configuration per setup (tie to scoring fn)\n",
    "# ----------------------------------------------------\n",
    "# Here we are encoding the CIAS datapath:\n",
    "# - Same CIAS block for both setups (same number of ops per window).\n",
    "# - 16 selected features, with ~5 adds and 2 multiplies per feature\n",
    "#   across E2, E1, and the final score → 80 adds, 32 mults.\n",
    "# - Die areas are approximate CPU die sizes in mm^2.\n",
    "\n",
    "SETUP_HW_CONFIG = {\n",
    "    \"A\": {\n",
    "        \"n_adders\": 1,\n",
    "        \"n_multipliers\": 1,\n",
    "        \"n_add_ops_per_eval\":  80,   # CIAS integer adds per window\n",
    "        \"n_mult_ops_per_eval\": 32,   # CIAS integer mults per window\n",
    "        \"die_area_mm2\": 125.0,       # ~i5-7600K die area (mm^2)\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"n_adders\": 1,\n",
    "        \"n_multipliers\": 1,\n",
    "        \"n_add_ops_per_eval\":  80,\n",
    "        \"n_mult_ops_per_eval\": 32,\n",
    "        \"die_area_mm2\": 215.25,       # ~i5-12600K die area (mm^2)\n",
    "    },\n",
    "}\n",
    "\n",
    "EXACT_HW_CSV = OUT_ROOT / \"EXACT_CIAS_hw_summary.csv\"\n",
    "hw_summary_df = compute_exact_hw_costs_for_setups(\n",
    "    HW_CSV,\n",
    "    SETUP_HW_CONFIG,\n",
    "    out_csv=EXACT_HW_CSV,\n",
    ")\n",
    "\n",
    "print(\"\\n[S10] EXACT CIAS hardware cost summary:\")\n",
    "print(hw_summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50ba62-d17e-4d95-a4e9-e790a53cb231",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5290d-7312-4dbb-8927-6613f46d5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# S10. Causal structure & ranks\n",
    "# ==============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# For plotting; if networkx is missing, plotting will be skipped but CSVs still work\n",
    "try:\n",
    "    import networkx as nx\n",
    "except ImportError:\n",
    "    nx = None\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _assign_feature_domain(feat: str) -> str:\n",
    "    \"\"\"\n",
    "    Heuristic mapping from feature name to domain:\n",
    "      - 'CORE'   : default, core performance counters\n",
    "      - 'MEMORY' : DRAM / LLC / IMC traffic\n",
    "      - 'SENSOR' : temperature / power / voltage sensors\n",
    "    \"\"\"\n",
    "    name = feat.lower()\n",
    "    if any(tok in name for tok in [\"temp\", \"therm\", \"pk\", \"pkg\", \"pwr\", \"power\", \"volt\", \"vcc\"]):\n",
    "        return \"SENSOR\"\n",
    "    if any(tok in name for tok in [\"dram\", \"mem\", \"imc\", \"unc_m\", \"llc\", \"l3\", \"l2\", \"dimm\"]):\n",
    "        return \"MEMORY\"\n",
    "    return \"CORE\"  # everything else treated as core performance counters\n",
    "\n",
    "\n",
    "def _build_causal_edges_from_corr(\n",
    "    corr_df: pd.DataFrame,\n",
    "    corr_threshold: float = 0.35,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Turn a correlation matrix into an edge list.\n",
    "    Keep edges with |rho| >= corr_threshold.\n",
    "    Edge direction follows CORE -> MEMORY -> SENSOR where possible.\n",
    "    \"\"\"\n",
    "    features = list(corr_df.columns)\n",
    "    domains = {f: _assign_feature_domain(f) for f in features}\n",
    "    domain_order = {\"CORE\": 0, \"MEMORY\": 1, \"SENSOR\": 2}\n",
    "\n",
    "    rows = []\n",
    "    for i, f_i in enumerate(features):\n",
    "        for j in range(i + 1, len(features)):\n",
    "            f_j = features[j]\n",
    "            rho = corr_df.iloc[i, j]\n",
    "            if not np.isfinite(rho):\n",
    "                continue\n",
    "            if abs(rho) < corr_threshold:\n",
    "                continue\n",
    "\n",
    "            dom_i = domains[f_i]\n",
    "            dom_j = domains[f_j]\n",
    "\n",
    "            if domain_order[dom_i] < domain_order[dom_j]:\n",
    "                src, dst = f_i, f_j\n",
    "            elif domain_order[dom_j] < domain_order[dom_i]:\n",
    "                src, dst = f_j, f_i\n",
    "            else:\n",
    "                # Same domain: orient by name just for consistency\n",
    "                src, dst = (f_i, f_j) if f_i <= f_j else (f_j, f_i)\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"src\": src,\n",
    "                    \"dst\": dst,\n",
    "                    \"rho\": float(rho),\n",
    "                    \"abs_rho\": float(abs(rho)),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def _compute_graph_centrality(\n",
    "    features: list[str],\n",
    "    edges_df: pd.DataFrame,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Simple degree centrality on the undirected version of the graph.\n",
    "    \"\"\"\n",
    "    n = max(len(features) - 1, 1)\n",
    "    deg_counts = {f: 0 for f in features}\n",
    "\n",
    "    if edges_df is None or edges_df.empty:\n",
    "        return {f: 0.0 for f in features}\n",
    "\n",
    "    for row in edges_df.itertuples():\n",
    "        deg_counts[row.src] += 1\n",
    "        deg_counts[row.dst] += 1\n",
    "\n",
    "    return {f: deg_counts[f] / n for f in features}\n",
    "\n",
    "\n",
    "def _compute_feature_cias_correlation(\n",
    "    df_Z: pd.DataFrame,\n",
    "    features: list[str],\n",
    "    score_col: str = \"cias_sample_score\",\n",
    "    scenarios: tuple = (\"DROOP\", \"RH\", \"SPECTRE\"),\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    For each feature, compute the average |Spearman rho| between that feature\n",
    "    and the CIAS sample score over the specified anomaly scenarios.\n",
    "    \"\"\"\n",
    "    corr_map = {f: [] for f in features}\n",
    "    df_Z = df_Z.copy()\n",
    "    df_Z[\"scenario\"] = df_Z[\"scenario\"].astype(str).str.upper()\n",
    "\n",
    "    for scen in scenarios:\n",
    "        scen_u = scen.upper()\n",
    "        df_s = df_Z[df_Z[\"scenario\"] == scen_u]\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "\n",
    "        for f in features:\n",
    "            if f not in df_s.columns:\n",
    "                continue\n",
    "            sub = df_s[[f, score_col]].dropna()\n",
    "            if sub[f].nunique() <= 1 or sub[score_col].nunique() <= 1:\n",
    "                continue\n",
    "            rho = sub.corr(method=\"spearman\").iloc[0, 1]\n",
    "            if np.isfinite(rho):\n",
    "                corr_map[f].append(abs(float(rho)))\n",
    "\n",
    "    # Average over scenarios (or 0 if never used)\n",
    "    corr_avg = {}\n",
    "    for f, vals in corr_map.items():\n",
    "        corr_avg[f] = float(np.mean(vals)) if vals else 0.0\n",
    "    return corr_avg\n",
    "\n",
    "\n",
    "def build_causal_and_feature_rank_csvs_for_setup(\n",
    "    setup: str,\n",
    "    df_Z: pd.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    out_root: Path,\n",
    "    corr_threshold: float = 0.35,\n",
    "    top_k_plot: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    For a given setup ('A' or 'B'), build:\n",
    "      - benign correlation-based causal edges\n",
    "      - node table with domains and importance scores r_f\n",
    "      - feature-rank CSV (sorted by importance)\n",
    "    and (optionally) a combined figure with the causal graph + top-K bar chart.\n",
    "    \"\"\"\n",
    "    setup = setup.upper()\n",
    "    df_setup = df_Z[df_Z[\"setup\"] == setup].copy()\n",
    "    if df_setup.empty:\n",
    "        raise ValueError(f\"No rows found for setup={setup} in df_Z.\")\n",
    "\n",
    "    # 1) Benign-only correlation structure\n",
    "    df_ben = df_setup[df_setup[\"scenario\"].astype(str).str.upper() == \"BENIGN\"].copy()\n",
    "    if df_ben.empty:\n",
    "        raise ValueError(f\"No BENIGN rows found for setup={setup}.\")\n",
    "\n",
    "    feats = [f for f in feature_cols if f in df_ben.columns]\n",
    "    if not feats:\n",
    "        raise ValueError(f\"None of the requested feature_cols are in BENIGN df for setup={setup}.\")\n",
    "\n",
    "    X_ben = df_ben[feats].astype(float)\n",
    "    corr_df = X_ben.corr(method=\"spearman\")\n",
    "\n",
    "    edges_df = _build_causal_edges_from_corr(corr_df, corr_threshold=corr_threshold)\n",
    "    centrality = _compute_graph_centrality(feats, edges_df)\n",
    "    cias_corr = _compute_feature_cias_correlation(\n",
    "        df_setup, feats, score_col=\"cias_sample_score\"\n",
    "    )\n",
    "\n",
    "    # 2) Importance scores \\tilde{r}_f: graph centrality × CIAS-alignment\n",
    "    graph_vec = np.array([centrality[f] for f in feats], dtype=float)\n",
    "    corr_vec = np.array([cias_corr[f] for f in feats], dtype=float)\n",
    "\n",
    "    # Normalize to [0,1] before combining\n",
    "    g_max = max(graph_vec.max(), 1e-8)\n",
    "    c_max = max(corr_vec.max(), 1e-8)\n",
    "    graph_norm = graph_vec / g_max\n",
    "    corr_norm = corr_vec / c_max\n",
    "\n",
    "    r_raw = graph_norm * corr_norm\n",
    "    r_max = max(r_raw.max(), 1e-8)\n",
    "    r_norm = r_raw / r_max\n",
    "\n",
    "    domains = {_f: _assign_feature_domain(_f) for _f in feats}\n",
    "\n",
    "    nodes_rows = []\n",
    "    ranks_rows = []\n",
    "    for f, g_c, c_c, r in zip(feats, graph_norm, corr_norm, r_norm):\n",
    "        nodes_rows.append(\n",
    "            {\n",
    "                \"feature\": f,\n",
    "                \"domain\": domains[f],\n",
    "                \"graph_centrality\": float(g_c),\n",
    "                \"cias_alignment\": float(c_c),\n",
    "                \"importance_score\": float(r),\n",
    "            }\n",
    "        )\n",
    "        ranks_rows.append(\n",
    "            {\n",
    "                \"feature\": f,\n",
    "                \"domain\": domains[f],\n",
    "                \"importance_score\": float(r),\n",
    "                \"graph_centrality\": float(g_c),\n",
    "                \"cias_alignment\": float(c_c),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    nodes_df = pd.DataFrame(nodes_rows)\n",
    "    ranks_df = pd.DataFrame(ranks_rows).sort_values(\n",
    "        \"importance_score\", ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # 3) Save CSVs\n",
    "    causal_dir = Path(out_root) / \"CAUSAL\"\n",
    "    causal_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    nodes_csv = causal_dir / f\"SETUP_{setup}_causal_nodes.csv\"\n",
    "    edges_csv = causal_dir / f\"SETUP_{setup}_causal_edges.csv\"\n",
    "    ranks_csv = causal_dir / f\"SETUP_{setup}_feature_ranks.csv\"\n",
    "\n",
    "    nodes_df.to_csv(nodes_csv, index=False)\n",
    "    edges_df.to_csv(edges_csv, index=False)\n",
    "    ranks_df.to_csv(ranks_csv, index=False)\n",
    "\n",
    "    print(f\"[CAUSAL] Saved nodes for setup {setup} to:   {nodes_csv}\")\n",
    "    print(f\"[CAUSAL] Saved edges for setup {setup} to:   {edges_csv}\")\n",
    "    print(f\"[CAUSAL] Saved ranks for setup {setup} to:   {ranks_csv}\")\n",
    "\n",
    "    # 4) Optional figure: causal graph + top-K bar chart\n",
    "    try:\n",
    "        if nx is None:\n",
    "            print(\"[CAUSAL] networkx not installed; skipping causal graph plot.\")\n",
    "            return nodes_df, edges_df, ranks_df\n",
    "\n",
    "        top_k = min(top_k_plot, len(ranks_df))\n",
    "        top_feats = ranks_df.head(top_k)[\"feature\"].tolist()\n",
    "        top_scores = ranks_df.head(top_k)[\"importance_score\"].to_numpy()\n",
    "        top_domains = [domains[f] for f in top_feats]\n",
    "\n",
    "        # Build graph for plotting (only features that appear in nodes_df; edges already filtered)\n",
    "        G = nx.DiGraph()\n",
    "        for row in nodes_rows:\n",
    "            G.add_node(\n",
    "                row[\"feature\"],\n",
    "                domain=row[\"domain\"],\n",
    "                importance=row[\"importance_score\"],\n",
    "            )\n",
    "\n",
    "        for row in edges_df.itertuples():\n",
    "            G.add_edge(row.src, row.dst, weight=row.abs_rho)\n",
    "\n",
    "        # Layout: arrange by domain (y) and spread within each domain (x)\n",
    "        domain_y = {\"CORE\": 0.0, \"MEMORY\": 1.0, \"SENSOR\": 2.0}\n",
    "        pos = {}\n",
    "        nodes_by_dom = {\"CORE\": [], \"MEMORY\": [], \"SENSOR\": []}\n",
    "        for n, data in G.nodes(data=True):\n",
    "            dom = data.get(\"domain\", \"CORE\")\n",
    "            nodes_by_dom.setdefault(dom, []).append(n)\n",
    "\n",
    "        for dom, nodes_dom in nodes_by_dom.items():\n",
    "            if not nodes_dom:\n",
    "                continue\n",
    "            xs = np.linspace(0.0, 1.0, len(nodes_dom))\n",
    "            y = domain_y.get(dom, 0.0)\n",
    "            for x, n in zip(xs, nodes_dom):\n",
    "                pos[n] = (x, y)\n",
    "\n",
    "        # Node colors by domain\n",
    "        color_map = {\"CORE\": \"#1f77b4\", \"MEMORY\": \"#ff7f0e\", \"SENSOR\": \"#2ca02c\"}\n",
    "        node_colors = [color_map.get(G.nodes[n].get(\"domain\", \"CORE\"), \"#1f77b4\")\n",
    "                       for n in G.nodes]\n",
    "        node_sizes = [\n",
    "            100 + 400 * G.nodes[n].get(\"importance\", 0.0) for n in G.nodes\n",
    "        ]\n",
    "        edge_widths = []\n",
    "        for _, _, d in G.edges(data=True):\n",
    "            w = d.get(\"weight\", 0.0) if isinstance(d, dict) else float(d)\n",
    "            edge_widths.append(1.0 + 3.0 * w)\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            1, 2, figsize=(10, 4), gridspec_kw={\"width_ratios\": [2.0, 1.0]}\n",
    "        )\n",
    "        ax0, ax1 = axes\n",
    "\n",
    "        # (a) causal graph\n",
    "        nx.draw_networkx(\n",
    "            G,\n",
    "            pos=pos,\n",
    "            ax=ax0,\n",
    "            node_color=node_colors,\n",
    "            node_size=node_sizes,\n",
    "            width=edge_widths,\n",
    "            with_labels=False,\n",
    "            arrows=True,\n",
    "            arrowstyle=\"-|>\",\n",
    "            arrowsize=10,\n",
    "        )\n",
    "        # Domain labels on the left\n",
    "        for dom, y in domain_y.items():\n",
    "            ax0.text(-0.1, y, dom, va=\"center\", ha=\"right\", fontsize=9)\n",
    "\n",
    "        ax0.set_title(f\"Setup {setup}: benign causal structure\")\n",
    "        ax0.set_axis_off()\n",
    "\n",
    "        # (b) top-K bar chart\n",
    "        y_pos = np.arange(top_k)\n",
    "        bar_colors = [color_map.get(d, \"#1f77b4\") for d in top_domains]\n",
    "        ax1.barh(y_pos, top_scores, color=bar_colors)\n",
    "        ax1.set_yticks(y_pos)\n",
    "        ax1.set_yticklabels(top_feats, fontsize=8)\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.set_xlabel(\"Importance $\\\\tilde{r}_f$\")\n",
    "        ax1.set_title(f\"Top-{top_k} influential features\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig_path = causal_dir / f\"SETUP_{setup}_causal_and_ranks.png\"\n",
    "        fig.savefig(fig_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(\n",
    "            f\"[CAUSAL] Saved combined causal + ranks figure for setup {setup} to:\\n\"\n",
    "            f\"  {fig_path}\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[CAUSAL] WARNING: failed to plot causal figure for setup {setup}: {e}\")\n",
    "\n",
    "    return nodes_df, edges_df, ranks_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78449a11-7312-46b9-b89a-12b7c6c82cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build causal CSVs + figures for both setups using the shared CIAS features\n",
    "nodes_A, edges_A, ranks_A = build_causal_and_feature_rank_csvs_for_setup(\n",
    "    setup=\"A\",\n",
    "    df_Z=telemetry_A_Z,\n",
    "    feature_cols=shared_features,\n",
    "    out_root=OUT_ROOT,\n",
    "    corr_threshold=0.35,   # adjust if you want sparser / denser graph\n",
    "    top_k_plot=20,         # how many bars to show in the right-hand subplot\n",
    ")\n",
    "\n",
    "nodes_B, edges_B, ranks_B = build_causal_and_feature_rank_csvs_for_setup(\n",
    "    setup=\"B\",\n",
    "    df_Z=telemetry_B_Z,\n",
    "    feature_cols=shared_features,\n",
    "    out_root=OUT_ROOT,\n",
    "    corr_threshold=0.35,\n",
    "    top_k_plot=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3b671-bd17-4ed7-89b8-5a0796cc1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# S9 — Visualize the causal skeleton for 3 domains (Compute / Memory / Sensors)\n",
    "#\n",
    "# This version supports:\n",
    "#   - Per-setup CSVs:\n",
    "#       SETUP_A_causal_edges.csv / SETUP_A_causal_nodes.csv\n",
    "#       SETUP_B_causal_edges.csv / SETUP_B_causal_nodes.csv\n",
    "#   - Either:\n",
    "#       results_dir / \"csv\" / <files>      (old layout), or\n",
    "#       results_dir / <files>              (when results_dir == CAUSAL folder)\n",
    "#\n",
    "# Expected columns:\n",
    "#   Edges CSV : src, dst, rho, abs_rho        (we use abs_rho as edge strength)\n",
    "#               or u, v, strength, domain_u, domain_v (legacy)\n",
    "#   Nodes CSV : feature, domain, ...\n",
    "#               domain in {CORE, MEMORY, SENSOR} (mapped to compute/memory/sensors)\n",
    "#\n",
    "# Usage examples:\n",
    "#   CAUSAL_DIR = Path(\"./results\")\n",
    "#   plot_three_domain_networks(CAUSAL_DIR, setup=\"A\")\n",
    "#   plot_three_domain_networks(CAUSAL_DIR, setup=\"B\")\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_three_domain_networks(results_dir: Path,\n",
    "                               setup=None,\n",
    "                               label_only_top_n: int = 10,\n",
    "                               spring_k_full: float = 10.0,\n",
    "                               spring_k_domain: float = 5.0,\n",
    "                               seed: int = 42,\n",
    "                               show_labels_on_main_graph: bool = False):\n",
    "    \"\"\"\n",
    "    Build and plot the 3-domain causal graph (compute / memory / sensors),\n",
    "    optionally using per-setup edges/nodes CSVs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results_dir : Path\n",
    "        Root directory for a given EXACT run, or the CAUSAL folder itself.\n",
    "        We look for CSVs in:\n",
    "          - results_dir / \"csv\" / ..., if that subfolder exists; else\n",
    "          - results_dir / ...\n",
    "    setup : {\"A\",\"B\",None}\n",
    "        Which setup's CSVs to use. If \"A\" or \"B\", we look for\n",
    "          SETUP_<setup>_causal_edges.csv\n",
    "          SETUP_<setup>_causal_nodes.csv\n",
    "        under the chosen CSV directory. If None, falls back to\n",
    "          causal_skeleton_edges.csv (legacy).\n",
    "    \"\"\"\n",
    "    import networkx as nx\n",
    "\n",
    "    results_dir = Path(results_dir)\n",
    "\n",
    "    # Detect whether results_dir already *is* the CAUSAL folder\n",
    "    csv_subdir = results_dir / \"csv\"\n",
    "    if csv_subdir.exists():\n",
    "        csv_dir = csv_subdir\n",
    "    else:\n",
    "        csv_dir = results_dir\n",
    "\n",
    "    fig_dir = results_dir / \"figures\"\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Pick edges and nodes files based on \"setup\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    default_edges = csv_dir / \"causal_skeleton_edges.csv\"\n",
    "    edges_p = default_edges\n",
    "    nodes_p = None\n",
    "\n",
    "    if setup is not None:\n",
    "        setup = str(setup).upper()\n",
    "        edges_candidate = csv_dir / f\"SETUP_{setup}_causal_edges.csv\"\n",
    "        nodes_candidate = csv_dir / f\"SETUP_{setup}_causal_nodes.csv\"\n",
    "\n",
    "        if edges_candidate.exists():\n",
    "            edges_p = edges_candidate\n",
    "            nodes_p = nodes_candidate if nodes_candidate.exists() else None\n",
    "            print(f\"[S9] Using per-setup edges file {edges_p.name} (setup={setup})\")\n",
    "            if nodes_p is None:\n",
    "                print(f\"[S9] WARNING: {nodes_candidate.name} not found; \"\n",
    "                      \"domains will be inferred from names.\")\n",
    "        else:\n",
    "            print(f\"[S9] Per-setup edges CSV {edges_candidate} not found; \"\n",
    "                  f\"falling back to {default_edges.name}\")\n",
    "\n",
    "    if not edges_p.exists():\n",
    "        print(f\"[S9] {edges_p} not found. Please make sure the causal edges CSV exists.\")\n",
    "        return\n",
    "\n",
    "    edges_df = pd.read_csv(edges_p)\n",
    "\n",
    "    nodes_df = None\n",
    "    if nodes_p is not None and nodes_p.exists():\n",
    "        nodes_df = pd.read_csv(nodes_p)\n",
    "        print(f\"[S9] Loaded node metadata from {nodes_p.name}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Standardize edge columns: u, v, strength\n",
    "    # -------------------------------------------------------------------------\n",
    "    # New CSVs use \"src\"/\"dst\"; old ones may already have \"u\"/\"v\".\n",
    "    if \"u\" not in edges_df.columns and \"src\" in edges_df.columns:\n",
    "        edges_df = edges_df.rename(columns={\"src\": \"u\", \"dst\": \"v\"})\n",
    "\n",
    "    # Strength: use abs_rho if present, else |rho|, else 1.0 fallback.\n",
    "    if \"strength\" not in edges_df.columns:\n",
    "        if \"abs_rho\" in edges_df.columns:\n",
    "            edges_df[\"strength\"] = edges_df[\"abs_rho\"].astype(float).abs()\n",
    "        elif \"rho\" in edges_df.columns:\n",
    "            edges_df[\"strength\"] = edges_df[\"rho\"].astype(float).abs()\n",
    "        else:\n",
    "            edges_df[\"strength\"] = 1.0\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3) Map node -> domain using nodes CSV when available\n",
    "    #     Nodes CSV has domain in {CORE, MEMORY, SENSOR}.\n",
    "    # -------------------------------------------------------------------------\n",
    "    feat_to_dom = {}\n",
    "    if nodes_df is not None and \"feature\" in nodes_df.columns and \"domain\" in nodes_df.columns:\n",
    "        dom_map = {\n",
    "            \"CORE\": \"compute\",\n",
    "            \"COMPUTE\": \"compute\",\n",
    "            \"CPU\": \"compute\",\n",
    "            \"MEMORY\": \"memory\",\n",
    "            \"MEM\": \"memory\",\n",
    "            \"CACHE\": \"memory\",\n",
    "            \"SENSOR\": \"sensors\",\n",
    "            \"SENSORS\": \"sensors\",\n",
    "        }\n",
    "        for _, row in nodes_df.iterrows():\n",
    "            feat = str(row[\"feature\"])\n",
    "            dom_raw = str(row[\"domain\"]).upper()\n",
    "            dom = dom_map.get(dom_raw)\n",
    "\n",
    "            # If it's some other label, fall back to name-based heuristics\n",
    "            if dom is None:\n",
    "                fl = feat.lower()\n",
    "                if any(k in fl for k in [\"temp\", \"power\", \"energy\", \"volt\"]):\n",
    "                    dom = \"sensors\"\n",
    "                elif any(k in fl for k in [\"l2\", \"l3\", \"mem\"]):\n",
    "                    dom = \"memory\"\n",
    "                elif any(k in fl for k in [\"core\", \"ipc\", \"inst\", \"cycle\"]):\n",
    "                    dom = \"compute\"\n",
    "                else:\n",
    "                    dom = \"other\"\n",
    "            feat_to_dom[feat] = dom\n",
    "\n",
    "    def _infer_domain_local(name: str) -> str:\n",
    "        \"\"\"Infer compute/memory/sensors/other using node CSV mapping if possible.\"\"\"\n",
    "        name = str(name)\n",
    "        if name in feat_to_dom:\n",
    "            return feat_to_dom[name]\n",
    "        lname = name.lower()\n",
    "        if any(k in lname for k in [\"temp\", \"power\", \"energy\", \"volt\"]):\n",
    "            return \"sensors\"\n",
    "        if any(k in lname for k in [\"l2\", \"l3\", \"mem\"]):\n",
    "            return \"memory\"\n",
    "        if any(k in lname for k in [\"core\", \"ipc\", \"inst\", \"cycle\"]):\n",
    "            return \"compute\"\n",
    "        return \"other\"\n",
    "\n",
    "    # Ensure domain_u / domain_v exist and are normalized to our 3 domains\n",
    "    if \"domain_u\" not in edges_df.columns or \"domain_v\" not in edges_df.columns:\n",
    "        print(\"[S9] domain_u/domain_v missing — deriving from node CSV or name patterns.\")\n",
    "        edges_df[\"domain_u\"] = edges_df[\"u\"].map(_infer_domain_local)\n",
    "        edges_df[\"domain_v\"] = edges_df[\"v\"].map(_infer_domain_local)\n",
    "    else:\n",
    "        # If they exist (legacy file), normalize to compute/memory/sensors\n",
    "        def _norm_dom(val):\n",
    "            if pd.isna(val):\n",
    "                return \"other\"\n",
    "            s = str(val).lower()\n",
    "            if s in [\"core\", \"cpu\", \"compute\"]:\n",
    "                return \"compute\"\n",
    "            if s in [\"mem\", \"memory\", \"cache\"]:\n",
    "                return \"memory\"\n",
    "            if s in [\"sensor\", \"sensors\", \"pvt\", \"thermal\", \"power\"]:\n",
    "                return \"sensors\"\n",
    "            return s\n",
    "        edges_df[\"domain_u\"] = edges_df[\"domain_u\"].map(_norm_dom)\n",
    "        edges_df[\"domain_v\"] = edges_df[\"domain_v\"].map(_norm_dom)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Normalize edge strength into [0,1] so color/width are comparable.\n",
    "    # -------------------------------------------------------------------------\n",
    "    s = edges_df[\"strength\"].astype(float).replace([np.inf, -np.inf], np.nan).fillna(0.0).values\n",
    "    if len(s) and np.nanmax(s) > np.nanmin(s):\n",
    "        s_norm = (s - np.nanmin(s)) / (np.nanmax(s) - np.nanmin(s))\n",
    "    else:\n",
    "        s_norm = np.zeros_like(s)\n",
    "    edges_df[\"strength_norm\"] = s_norm\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Build an undirected graph: nodes = signals, edges = discovered links.\n",
    "    # -------------------------------------------------------------------------\n",
    "    G = nx.Graph()\n",
    "    for _, r in edges_df.iterrows():\n",
    "        u, v = str(r[\"u\"]), str(r[\"v\"])\n",
    "        w = float(r[\"strength_norm\"])\n",
    "        du, dv = str(r[\"domain_u\"]).lower(), str(r[\"domain_v\"]).lower()\n",
    "        G.add_node(u)\n",
    "        G.add_node(v)\n",
    "        G.add_edge(u, v, strength=w, domain_u=du, domain_v=dv)\n",
    "\n",
    "    print(f\"[S9] Full graph → nodes={G.number_of_nodes()} edges={G.number_of_edges()}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Assign a domain to each node via majority vote over incident edges.\n",
    "    #     (We keep only compute / memory / sensors; everything else is \"other\".)\n",
    "    # -------------------------------------------------------------------------\n",
    "    domain_counts = {}\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        for node, dn in [(u, d.get(\"domain_u\", \"other\")), (v, d.get(\"domain_v\", \"other\"))]:\n",
    "            if node not in domain_counts:\n",
    "                domain_counts[node] = {\"compute\": 0, \"memory\": 0, \"sensors\": 0, \"other\": 0}\n",
    "            if dn in domain_counts[node]:\n",
    "                domain_counts[node][dn] += 1\n",
    "            else:\n",
    "                domain_counts[node][\"other\"] += 1\n",
    "\n",
    "    def pick_majority(dct):\n",
    "        # Priority if there is a tie: compute > memory > sensors > other\n",
    "        order = [\"compute\", \"memory\", \"sensors\", \"other\"]\n",
    "        m = max(dct.values()) if dct else 0\n",
    "        cands = [k for k, v in dct.items() if v == m]\n",
    "        for k in order:\n",
    "            if k in cands:\n",
    "                return k\n",
    "        return \"other\"\n",
    "\n",
    "    node_domain = {n: pick_majority(domain_counts.get(n, {})) for n in G.nodes()}\n",
    "    keep_nodes = [n for n, dn in node_domain.items() if dn in {\"compute\", \"memory\", \"sensors\"}]\n",
    "    G3 = G.subgraph(keep_nodes).copy()\n",
    "    print(f\"[S9] 3-domain graph → nodes={G3.number_of_nodes()} edges={G3.number_of_edges()}\")\n",
    "\n",
    "    # Degree (number of neighbors) is used to scale node size and pick labels.\n",
    "    deg = dict(G3.degree())\n",
    "    if deg:\n",
    "        dmax, dmin = max(deg.values()), min(deg.values())\n",
    "    else:\n",
    "        dmax = dmin = 1\n",
    "\n",
    "    def scale_size(d):\n",
    "        # Larger range for nicer PPT figures\n",
    "        if dmax == dmin:\n",
    "            return 1800.0\n",
    "        return 1800.0 + 1500.0 * (d - dmin) / (dmax - dmin)\n",
    "\n",
    "    # Pastel domain colors for PPT\n",
    "    domain_colors = {\n",
    "        \"compute\": \"#9ecae1\",  # light blue\n",
    "        \"memory\":  \"#a1d99b\",  # light green\n",
    "        \"sensors\": \"#fdae6b\",  # light orange\n",
    "    }\n",
    "\n",
    "    # VERY LARGE FONT SETTINGS FOR PRESENTATIONS\n",
    "    rc = {\n",
    "        \"font.size\": 36,\n",
    "        \"axes.titlesize\": 44,\n",
    "        \"axes.labelsize\": 40,\n",
    "        \"legend.fontsize\": 38,\n",
    "        \"xtick.labelsize\": 32,\n",
    "        \"ytick.labelsize\": 32,\n",
    "        \"figure.titlesize\": 48,\n",
    "    }\n",
    "\n",
    "    with plt.rc_context(rc):\n",
    "\n",
    "        # =========================\n",
    "        # (A) Full 3-domain network - NO FEATURE NAMES (clean presentation)\n",
    "        # =========================\n",
    "        if G3.number_of_nodes() > 0:\n",
    "            print(\"[S9] Laying out full 3-domain graph (no feature names)...\")\n",
    "            pos = nx.spring_layout(G3, k=spring_k_full, iterations=200, seed=seed)\n",
    "\n",
    "            node_sizes = [scale_size(deg[n]) for n in G3.nodes()]\n",
    "            node_colors_seq = [\n",
    "                domain_colors.get(node_domain.get(n, \"compute\"), \"#9ecae1\")\n",
    "                for n in G3.nodes()\n",
    "            ]\n",
    "            edge_strengths = [G3[u][v].get(\"strength\", 0.0) for u, v in G3.edges()]\n",
    "            edge_colors = [plt.cm.viridis(x) for x in edge_strengths]\n",
    "            edge_widths = [2.2 + 5.0 * x for x in edge_strengths]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(32, 28))\n",
    "            ax.margins(0.10)\n",
    "\n",
    "            # Draw edges first (so nodes appear on top)\n",
    "            nx.draw_networkx_edges(\n",
    "                G3, pos,\n",
    "                edge_color=edge_colors,\n",
    "                width=edge_widths,\n",
    "                alpha=0.45,\n",
    "                ax=ax,\n",
    "            )\n",
    "\n",
    "            # Draw nodes (larger and more visible since no labels)\n",
    "            nx.draw_networkx_nodes(\n",
    "                G3, pos,\n",
    "                node_size=node_sizes,\n",
    "                node_color=node_colors_seq,\n",
    "                alpha=0.96,\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=2.2,\n",
    "                ax=ax,\n",
    "            )\n",
    "\n",
    "            title_suffix = f\" (Setup {setup})\" if setup is not None else \"\"\n",
    "            ax.set_title(f\"High-Density Causal Skeleton{title_suffix}\\n\"\n",
    "                         \"(Compute / Memory / Sensors only)\",\n",
    "                         fontweight=\"bold\", pad=28)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # Legend outside plot so it never covers nodes\n",
    "            from matplotlib.patches import Patch\n",
    "            legend_elements = [\n",
    "                Patch(facecolor=domain_colors[\"compute\"],\n",
    "                      label=\"Compute features\",\n",
    "                      alpha=0.95),\n",
    "                Patch(facecolor=domain_colors[\"memory\"],\n",
    "                      label=\"Memory features\",\n",
    "                      alpha=0.95),\n",
    "                Patch(facecolor=domain_colors[\"sensors\"],\n",
    "                      label=\"Sensor features\",\n",
    "                      alpha=0.95),\n",
    "            ]\n",
    "            ax.legend(\n",
    "                handles=legend_elements,\n",
    "                loc=\"upper left\",\n",
    "                bbox_to_anchor=(1.02, 1.0),\n",
    "                borderaxespad=0.0,\n",
    "                frameon=True,\n",
    "                framealpha=0.95,\n",
    "                fontsize=34,\n",
    "            )\n",
    "\n",
    "            # Edge-strength colorbar\n",
    "            if edge_strengths:\n",
    "                sm = plt.cm.ScalarMappable(\n",
    "                    cmap=plt.cm.viridis,\n",
    "                    norm=plt.Normalize(vmin=min(edge_strengths),\n",
    "                                       vmax=max(edge_strengths)),\n",
    "                )\n",
    "                sm.set_array([])\n",
    "                cbar = fig.colorbar(sm, ax=ax, shrink=0.85,\n",
    "                                    aspect=30, pad=0.04)\n",
    "                cbar.set_label(\"Connection strength (normalized)\",\n",
    "                               rotation=270, labelpad=32, fontsize=38)\n",
    "                cbar.ax.tick_params(labelsize=32)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            base_name = \"high_density_causal_skeleton_no_other\"\n",
    "            if setup is not None:\n",
    "                base_name = f\"{base_name}_setup_{setup}\"\n",
    "            _safe_savefig(fig_dir / f\"{base_name}.png\", fig)\n",
    "            print(f\"💾 Saved → {fig_dir / f'{base_name}.png'}\")\n",
    "\n",
    "            # ===========================================\n",
    "            # (A2) Optional: Same graph WITH feature names\n",
    "            # ===========================================\n",
    "            if show_labels_on_main_graph:\n",
    "                print(\"[S9] Creating alternative version WITH feature names...\")\n",
    "                fig2, ax2 = plt.subplots(figsize=(32, 28))\n",
    "                ax2.margins(0.10)\n",
    "\n",
    "                # Draw everything again\n",
    "                nx.draw_networkx_edges(\n",
    "                    G3, pos,\n",
    "                    edge_color=edge_colors,\n",
    "                    width=edge_widths,\n",
    "                    alpha=0.45,\n",
    "                    ax=ax2,\n",
    "                )\n",
    "                nx.draw_networkx_nodes(\n",
    "                    G3, pos,\n",
    "                    node_size=[s * 0.9 for s in node_sizes],  # Slightly smaller for labels\n",
    "                    node_color=node_colors_seq,\n",
    "                    alpha=0.96,\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidths=2.2,\n",
    "                    ax=ax2,\n",
    "                )\n",
    "\n",
    "                # Add labels for top nodes only\n",
    "                top_nodes = [n for n, _ in sorted(deg.items(),\n",
    "                                                  key=lambda t: t[1],\n",
    "                                                  reverse=True)[:label_only_top_n]]\n",
    "\n",
    "                def clean_name(n):\n",
    "                    if \"Core\" in n and \"Socket\" in n:\n",
    "                        parts = n.split('.')\n",
    "                        try:\n",
    "                            core_num = n.split('(')[1].split()[0]\n",
    "                            metric = parts[1].split('_')[-1] if len(parts) > 1 else \"M\"\n",
    "                            return f\"C{core_num}.{metric}\"\n",
    "                        except Exception:\n",
    "                            return n[:15] + \"...\" if len(n) > 15 else n\n",
    "                    if \"System\" in n:\n",
    "                        parts = n.split('.')\n",
    "                        return f\"Sys.{parts[1]}\" if len(parts) > 1 else \"System\"\n",
    "                    if \"Socket\" in n and \"Core\" not in n:\n",
    "                        parts = n.split('.')\n",
    "                        return f\"SKT.{parts[1]}\" if len(parts) > 1 else \"Socket\"\n",
    "                    # General shortening for other nodes\n",
    "                    if len(n) > 20:\n",
    "                        return n[:18] + \"...\"\n",
    "                    return n\n",
    "\n",
    "                labels = {n: clean_name(n) for n in top_nodes}\n",
    "                nx.draw_networkx_labels(\n",
    "                    G3,\n",
    "                    {n: pos[n] for n in top_nodes},\n",
    "                    labels,\n",
    "                    font_size=24,\n",
    "                    font_weight=\"bold\",\n",
    "                    ax=ax2,\n",
    "                    bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.85, pad=0.20),\n",
    "                )\n",
    "\n",
    "                ax2.set_title(\n",
    "                    f\"High-Density Causal Skeleton (With Labels){title_suffix}\\n\"\n",
    "                    \"(Compute / Memory / Sensors only)\",\n",
    "                    fontweight=\"bold\", pad=28,\n",
    "                )\n",
    "                ax2.axis(\"off\")\n",
    "\n",
    "                # Add legend\n",
    "                ax2.legend(\n",
    "                    handles=legend_elements,\n",
    "                    loc=\"upper left\",\n",
    "                    bbox_to_anchor=(1.02, 1.0),\n",
    "                    borderaxespad=0.0,\n",
    "                    frameon=True,\n",
    "                    framealpha=0.95,\n",
    "                    fontsize=34,\n",
    "                )\n",
    "\n",
    "                # Add colorbar\n",
    "                if edge_strengths:\n",
    "                    sm2 = plt.cm.ScalarMappable(\n",
    "                        cmap=plt.cm.viridis,\n",
    "                        norm=plt.Normalize(vmin=min(edge_strengths),\n",
    "                                           vmax=max(edge_strengths)),\n",
    "                    )\n",
    "                    sm2.set_array([])\n",
    "                    cbar2 = fig2.colorbar(sm2, ax=ax2, shrink=0.85,\n",
    "                                          aspect=30, pad=0.04)\n",
    "                    cbar2.set_label(\"Connection strength (normalized)\",\n",
    "                                    rotation=270, labelpad=32, fontsize=38)\n",
    "                    cbar2.ax.tick_params(labelsize=32)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                base_name2 = \"high_density_causal_skeleton_with_labels\"\n",
    "                if setup is not None:\n",
    "                    base_name2 = f\"{base_name2}_setup_{setup}\"\n",
    "                _safe_savefig(fig_dir / f\"{base_name2}.png\", fig2)\n",
    "                print(f\"💾 Saved (with labels) → {fig_dir / f'{base_name2}.png'}\")\n",
    "\n",
    "        else:\n",
    "            print(\"[S9] 3-domain graph is empty; skipping full plot.\")\n",
    "\n",
    "        # ==================================\n",
    "        # (B) Domain-specific subgraphs (3x)\n",
    "        # ==================================\n",
    "        domains = [\"compute\", \"memory\", \"sensors\"]\n",
    "\n",
    "        # ---- Combined 3-panel figure ----\n",
    "        fig_comb, axes = plt.subplots(1, 3, figsize=(36, 14))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, dom in enumerate(domains):\n",
    "            dn_nodes = [n for n in G3.nodes() if node_domain.get(n) == dom]\n",
    "            ax = axes[i]\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(f\"{dom.capitalize()} domain ({len(dn_nodes)} nodes)\",\n",
    "                         fontsize=40, fontweight=\"bold\", pad=20)\n",
    "            if len(dn_nodes) < 2:\n",
    "                continue\n",
    "\n",
    "            H = G3.subgraph(dn_nodes).copy()\n",
    "            pos_sub = nx.spring_layout(H, k=spring_k_domain, iterations=150, seed=seed)\n",
    "\n",
    "            node_sizes_sub = [scale_size(deg.get(n, 1)) for n in H.nodes()]\n",
    "            nx.draw_networkx_nodes(\n",
    "                H, pos_sub,\n",
    "                node_size=node_sizes_sub,\n",
    "                node_color=domain_colors[dom],\n",
    "                alpha=0.96,\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=2.0,\n",
    "                ax=ax,\n",
    "            )\n",
    "\n",
    "            dom_edges = list(H.edges())\n",
    "            if dom_edges:\n",
    "                es = [H[u][v].get(\"strength\", 0.0) for u, v in dom_edges]\n",
    "                ec = [plt.cm.viridis(x) for x in es]\n",
    "                ew = [1.8 + 4.0 * x for x in es]\n",
    "                nx.draw_networkx_edges(\n",
    "                    H, pos_sub,\n",
    "                    edgelist=dom_edges,\n",
    "                    edge_color=ec,\n",
    "                    width=ew,\n",
    "                    alpha=0.55,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "            dom_deg = dict(H.degree())\n",
    "            dom_top = [n for n, _ in sorted(dom_deg.items(),\n",
    "                                            key=lambda t: t[1],\n",
    "                                            reverse=True)[:max(3, label_only_top_n // 3)]]\n",
    "            nx.draw_networkx_labels(\n",
    "                H, pos_sub,\n",
    "                {n: n[:15] + \"...\" if len(n) > 15 else n for n in dom_top},\n",
    "                font_size=24,\n",
    "                font_weight=\"bold\",\n",
    "                ax=ax,\n",
    "                bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.85, pad=0.18),\n",
    "            )\n",
    "\n",
    "        sup_title_suffix = f\" (Setup {setup})\" if setup is not None else \"\"\n",
    "        plt.suptitle(f\"Causal Skeleton — Domain-Specific Views{sup_title_suffix}\",\n",
    "                     fontsize=44, fontweight=\"bold\", y=0.98)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        combo_name = \"three_domain_networks_high_density\"\n",
    "        if setup is not None:\n",
    "            combo_name = f\"{combo_name}_setup_{setup}\"\n",
    "        _safe_savefig(fig_dir / f\"{combo_name}.png\", fig_comb)\n",
    "        print(f\"💾 Saved → {fig_dir / f'{combo_name}.png'}\")\n",
    "\n",
    "        # ---- Separate PNG per domain (for PPT) ----\n",
    "        for dom in domains:\n",
    "            dn_nodes = [n for n in G3.nodes() if node_domain.get(n) == dom]\n",
    "            if len(dn_nodes) < 2:\n",
    "                continue\n",
    "\n",
    "            H = G3.subgraph(dn_nodes).copy()\n",
    "            pos_sub = nx.spring_layout(H, k=spring_k_domain, iterations=150, seed=seed)\n",
    "\n",
    "            fig_d, ax_d = plt.subplots(figsize=(22, 18))\n",
    "            ax_d.axis(\"off\")\n",
    "            ax_d.set_title(f\"{dom.capitalize()} domain ({len(dn_nodes)} nodes){sup_title_suffix}\",\n",
    "                           fontsize=44, fontweight=\"bold\", pad=22)\n",
    "\n",
    "            node_sizes_sub = [scale_size(deg.get(n, 1)) for n in H.nodes()]\n",
    "            nx.draw_networkx_nodes(\n",
    "                H, pos_sub,\n",
    "                node_size=node_sizes_sub,\n",
    "                node_color=domain_colors[dom],\n",
    "                alpha=0.96,\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=2.2,\n",
    "                ax=ax_d,\n",
    "            )\n",
    "\n",
    "            dom_edges = list(H.edges())\n",
    "            if dom_edges:\n",
    "                es = [H[u][v].get(\"strength\", 0.0) for u, v in dom_edges]\n",
    "                ec = [plt.cm.viridis(x) for x in es]\n",
    "                ew = [2.0 + 4.5 * x for x in es]\n",
    "                nx.draw_networkx_edges(\n",
    "                    H, pos_sub,\n",
    "                    edgelist=dom_edges,\n",
    "                    edge_color=ec,\n",
    "                    width=ew,\n",
    "                    alpha=0.55,\n",
    "                    ax=ax_d,\n",
    "                )\n",
    "\n",
    "            dom_deg = dict(H.degree())\n",
    "            dom_top = [n for n, _ in sorted(dom_deg.items(),\n",
    "                                            key=lambda t: t[1],\n",
    "                                            reverse=True)[:max(4, label_only_top_n // 2)]]\n",
    "            nx.draw_networkx_labels(\n",
    "                H, pos_sub,\n",
    "                {n: n[:12] + \"...\" if len(n) > 12 else n for n in dom_top},\n",
    "                font_size=26,\n",
    "                font_weight=\"bold\",\n",
    "                ax=ax_d,\n",
    "                bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.9, pad=0.18),\n",
    "            )\n",
    "\n",
    "            plt.tight_layout()\n",
    "            out_dom = fig_dir / f\"domain_{dom}_network_high_density\"\n",
    "            if setup is not None:\n",
    "                out_dom = out_dom.with_name(out_dom.name + f\"_setup_{setup}.png\")\n",
    "            else:\n",
    "                out_dom = out_dom.with_suffix(\".png\")\n",
    "            _safe_savefig(out_dom, fig_d)\n",
    "            print(f\"💾 Saved → {out_dom}\")\n",
    "\n",
    "        # =======================================\n",
    "        # (C) Core-focused circular visualization\n",
    "        #     Zoom in on per-core compute relationships.\n",
    "        # =======================================\n",
    "        core_nodes = [n for n in G3.nodes() if (\"Core\" in n and \"Socket\" in n)]\n",
    "        Hcore = G3.subgraph(core_nodes).copy()\n",
    "        print(f\"[S9] Core subgraph → nodes={Hcore.number_of_nodes()} edges={Hcore.number_of_edges()}\")\n",
    "\n",
    "        if Hcore.number_of_nodes() > 0:\n",
    "            pos_core = nx.circular_layout(Hcore)\n",
    "            node_sizes_core = [scale_size(deg.get(n, 1)) for n in Hcore.nodes()]\n",
    "            node_colors_core = [\n",
    "                domain_colors.get(node_domain.get(n, \"compute\"), \"#9ecae1\")\n",
    "                for n in Hcore.nodes()\n",
    "            ]\n",
    "\n",
    "            fig3, ax3 = plt.subplots(figsize=(30, 26))\n",
    "            ax3.margins(0.15)\n",
    "\n",
    "            nx.draw_networkx_nodes(\n",
    "                Hcore, pos_core,\n",
    "                node_size=node_sizes_core,\n",
    "                node_color=node_colors_core,\n",
    "                alpha=0.96,\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=2.2,\n",
    "                ax=ax3,\n",
    "            )\n",
    "            core_edges = list(Hcore.edges())\n",
    "            if core_edges:\n",
    "                es = [Hcore[u][v].get(\"strength\", 0.0) for u, v in core_edges]\n",
    "                ec = [plt.cm.viridis(x) for x in es]\n",
    "                ew = [1.6 + 3.5 * x for x in es]\n",
    "                nx.draw_networkx_edges(\n",
    "                    Hcore, pos_core,\n",
    "                    edgelist=core_edges,\n",
    "                    edge_color=ec,\n",
    "                    width=ew,\n",
    "                    alpha=0.45,\n",
    "                    ax=ax3,\n",
    "                )\n",
    "\n",
    "            # Compact labels: C#.<metric>\n",
    "            labels_core = {}\n",
    "            for n in Hcore.nodes():\n",
    "                try:\n",
    "                    core_num = n.split('(')[1].split()[0]\n",
    "                    metric = (n.split('.', 1)[1].split('_')[-1]) if ('.' in n) else \"M\"\n",
    "                    labels_core[n] = f\"C{core_num}.{metric}\"\n",
    "                except Exception:\n",
    "                    labels_core[n] = n[:10] + \"...\" if len(n) > 10 else n\n",
    "\n",
    "            nx.draw_networkx_labels(\n",
    "                Hcore, pos_core,\n",
    "                labels_core,\n",
    "                font_size=26,\n",
    "                font_weight=\"bold\",\n",
    "                ax=ax3,\n",
    "                bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.9, pad=0.18),\n",
    "            )\n",
    "\n",
    "            title = \"Core-Level Causal Relationships (Compute)\"\n",
    "            if setup is not None:\n",
    "                title += f\" — Setup {setup}\"\n",
    "            ax3.set_title(title, fontsize=44, fontweight=\"bold\", pad=24)\n",
    "            ax3.axis(\"off\")\n",
    "\n",
    "            if core_edges:\n",
    "                sm3 = plt.cm.ScalarMappable(\n",
    "                    cmap=plt.cm.viridis,\n",
    "                    norm=plt.Normalize(vmin=min(es), vmax=max(es)),\n",
    "                )\n",
    "                sm3.set_array([])\n",
    "                cbar3 = fig3.colorbar(sm3, ax=ax3, shrink=0.80,\n",
    "                                      aspect=30, pad=0.04)\n",
    "                cbar3.set_label(\"Connection strength (normalized)\",\n",
    "                                rotation=270, labelpad=32, fontsize=38)\n",
    "                cbar3.ax.tick_params(labelsize=32)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            core_name = \"core_network_circular_high_density\"\n",
    "            if setup is not None:\n",
    "                core_name = f\"{core_name}_setup_{setup}\"\n",
    "            _safe_savefig(fig_dir / f\"{core_name}.png\", fig3)\n",
    "            print(f\"💾 Saved → {fig_dir / f'{core_name}.png'}\")\n",
    "\n",
    "    # ================\n",
    "    # Textual summary\n",
    "    # ================\n",
    "    dom_counts = {\"compute\": 0, \"memory\": 0, \"sensors\": 0}\n",
    "    for n, d in node_domain.items():\n",
    "        if n in G3 and d in dom_counts:\n",
    "            dom_counts[d] += 1\n",
    "\n",
    "    deg_sorted = sorted(deg.items(), key=lambda t: t[1], reverse=True)\n",
    "    summary_name = \"three_domain_summary.txt\" if setup is None else f\"three_domain_summary_setup_{setup}.txt\"\n",
    "    summary_txt = fig_dir / summary_name\n",
    "    with open(summary_txt, \"w\") as f:\n",
    "        f.write(\"HIGH-DENSITY 3-DOMAIN SKELETON SUMMARY\\n\")\n",
    "        f.write(f\"nodes={G3.number_of_nodes()} edges={G3.number_of_edges()}\\n\")\n",
    "        f.write(\"domain_counts=\" + json.dumps(dom_counts) + \"\\n\")\n",
    "        f.write(\"top_degree_nodes:\\n\")\n",
    "        for n, d in deg_sorted[:20]:\n",
    "            f.write(f\"  {n}  deg={d}  domain={node_domain.get(n, '?')}\\n\")\n",
    "    print(f\"📝 Summary saved → {summary_txt.name}\")\n",
    "\n",
    "\n",
    "def run_S9_for(out: dict, setup=None):\n",
    "    \"\"\"\n",
    "    Small helper: call S9 after S8 using the `out` dict that holds results_dir.\n",
    "    If setup is not given, will try out.get(\"setup\") or out.get(\"setup_label\").\n",
    "    \"\"\"\n",
    "    setup_use = setup or out.get(\"setup\") or out.get(\"setup_label\")\n",
    "    return plot_three_domain_networks(out[\"results_dir\"], setup=setup_use)\n",
    "\n",
    "\n",
    "# Helper function for saving figures (add if missing)\n",
    "def _safe_savefig(path, fig, dpi=150, bbox_inches='tight'):\n",
    "    \"\"\"Save figure with error handling.\"\"\"\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        fig.savefig(path, dpi=dpi, bbox_inches=bbox_inches)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save {path}: {e}\")\n",
    "        # Try with lower DPI\n",
    "        try:\n",
    "            fig.savefig(path, dpi=100, bbox_inches=bbox_inches)\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186137fe-7762-4e00-9b5b-f0a59b1ba399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "CAUSAL_DIR = Path(\"./results\")\n",
    "\n",
    "plot_three_domain_networks(CAUSAL_DIR, setup=\"A\")\n",
    "plot_three_domain_networks(CAUSAL_DIR, setup=\"B\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e33f74-0f1f-484e-822f-1d30778ec511",
   "metadata": {},
   "source": [
    "### Trade-off: Window size vs. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda11e4-e51a-4188-8e73-a7b716b3c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# S11 – Window-size trade-off: bal_acc & MCC\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUT_ROOT = Path(\"./results\")  # same as S0/S6\n",
    "\n",
    "def load_balacc_mcc_vs_W(setup: str,\n",
    "                         scenarios=(\"DROOP\", \"RH\", \"SPECTRE\"),\n",
    "                         out_root: Path = OUT_ROOT) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load per-workload summary and average balanced accuracy (bal_acc)\n",
    "    and MCC over workloads and anomaly scenarios for each window size W.\n",
    "    \"\"\"\n",
    "    per_wl_csv = out_root / f\"SETUP_{setup}_EXACT_summary_per_workload.csv\"\n",
    "    df = pd.read_csv(per_wl_csv)\n",
    "\n",
    "    # Keep only requested anomaly scenarios (drop BENIGN rows if present)\n",
    "    if \"scenario\" in df.columns and scenarios is not None:\n",
    "        df = df[df[\"scenario\"].isin(scenarios)]\n",
    "\n",
    "    # Group by window size (and optionally n_splits if you want)\n",
    "    grp_cols = [\"window_size\"]\n",
    "    agg = (\n",
    "        df.groupby(grp_cols, as_index=False)\n",
    "          .agg(\n",
    "              bal_acc=(\"bal_acc\", \"mean\"),\n",
    "              mcc=(\"mcc\", \"mean\"),\n",
    "              n_test=(\"n_test\", \"mean\"),\n",
    "          )\n",
    "          .sort_values(\"window_size\")\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "\n",
    "def find_breakpoint(df: pd.DataFrame,\n",
    "                    metric: str,\n",
    "                    threshold: float = 0.99) -> int | None:\n",
    "    \"\"\"\n",
    "    Return the smallest window_size where the given metric drops below\n",
    "    'threshold'. If this never happens, return None.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\"window_size\")\n",
    "    bad = df[df[metric] < threshold]\n",
    "    if not bad.empty:\n",
    "        return int(bad[\"window_size\"].iloc[0])\n",
    "    return None\n",
    "\n",
    "\n",
    "# ---- Load curves for both setups ----\n",
    "balacc_mcc_A = load_balacc_mcc_vs_W(\"A\")\n",
    "balacc_mcc_B = load_balacc_mcc_vs_W(\"B\")\n",
    "\n",
    "print(\"Setup A – balanced accuracy & MCC vs window size:\")\n",
    "print(balacc_mcc_A.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "print(\"\\nSetup B – balanced accuracy & MCC vs window size:\")\n",
    "print(balacc_mcc_B.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# ---- Find where things 'start going bad' (example: < 0.99) ----\n",
    "thr = 0.99  # you can change to 0.98 or 0.95 if you prefer\n",
    "\n",
    "for setup, df in [(\"A\", balacc_mcc_A), (\"B\", balacc_mcc_B)]:\n",
    "    wb_bal = find_breakpoint(df, \"bal_acc\", threshold=thr)\n",
    "    wb_mcc = find_breakpoint(df, \"mcc\", threshold=thr)\n",
    "\n",
    "    print(f\"\\n[Setup {setup}] first window size with bal_acc < {thr}: {wb_bal}\")\n",
    "    print(f\"[Setup {setup}] first window size with MCC     < {thr}: {wb_mcc}\")\n",
    "\n",
    "# ---- Plot: two panels, bal_acc and MCC vs W ----\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "\n",
    "ax1, ax2 = axes\n",
    "\n",
    "# Balanced accuracy panel\n",
    "ax1.plot(balacc_mcc_A[\"window_size\"], balacc_mcc_A[\"bal_acc\"],\n",
    "         marker=\"o\", linestyle=\"-\", label=\"Setup A\")\n",
    "ax1.plot(balacc_mcc_B[\"window_size\"], balacc_mcc_B[\"bal_acc\"],\n",
    "         marker=\"s\", linestyle=\"--\", label=\"Setup B\")\n",
    "ax1.set_xlabel(\"Window size $W$\")\n",
    "ax1.set_ylabel(\"Balanced accuracy\")\n",
    "ax1.set_title(\"Balanced accuracy vs. window size\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0.0, 1.01)\n",
    "\n",
    "# MCC panel\n",
    "ax2.plot(balacc_mcc_A[\"window_size\"], balacc_mcc_A[\"mcc\"],\n",
    "         marker=\"o\", linestyle=\"-\", label=\"Setup A\")\n",
    "ax2.plot(balacc_mcc_B[\"window_size\"], balacc_mcc_B[\"mcc\"],\n",
    "         marker=\"s\", linestyle=\"--\", label=\"Setup B\")\n",
    "ax2.set_xlabel(\"Window size $W$\")\n",
    "ax2.set_ylabel(\"MCC\")\n",
    "ax2.set_title(\"MCC vs. window size\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(-0.05, 1.01)\n",
    "\n",
    "# Shared legend\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"lower center\", ncol=2, bbox_to_anchor=(0.5, -0.02))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.20)\n",
    "\n",
    "out_fig = OUT_ROOT / \"EXACT_balacc_mcc_vs_W_50_to_1000.png\"\n",
    "plt.savefig(out_fig, dpi=300)\n",
    "print(f\"\\nSaved figure to: {out_fig}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7a359-d761-4fba-9f55-e273f6480358",
   "metadata": {},
   "source": [
    "# **Hardware comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cedec1b-ffff-40bd-9617-e6344af046e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 1) Baselines and constants\n",
    "# ============================================================\n",
    "\n",
    "# Setup B die area (mm^2)\n",
    "SETUP_B_DIE_AREA_MM2 = 215.25\n",
    "\n",
    "# Workload powers on DDR5 platform (W) – non-idle\n",
    "POWER_WORKLOAD = {\n",
    "    \"DFT\": 139.5,\n",
    "    \"DJ\": 64.7,\n",
    "    \"DP\": 99.3,\n",
    "    \"GS\": 96.55,\n",
    "    \"GL\": 69.1,\n",
    "    \"HA\": 87.5,\n",
    "    \"JA\": 89.8,\n",
    "    \"MM\": 141.5,\n",
    "    \"NI\": 97.5,\n",
    "    \"OE\": 114.7,\n",
    "    \"PI\": 96.8,\n",
    "    \"SH\": 113.0,\n",
    "    \"TR\": 94.9,\n",
    "}\n",
    "\n",
    "workload_powers = np.array(list(POWER_WORKLOAD.values()))\n",
    "median_workload_power_W = np.median(workload_powers)\n",
    "\n",
    "# Idle power baseline (W) – from your earlier comment\n",
    "IDLE_POWER_W = 35.5\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EXACT (CIAS) parameters\n",
    "# ------------------------------------------------------------\n",
    "EXACT_AREA_MM2 = 0.0057\n",
    "EXACT_AREA_OVERHEAD_PCT = 100.0 * EXACT_AREA_MM2 / SETUP_B_DIE_AREA_MM2\n",
    "\n",
    "# Given: 0.0032% median overhead relative to workload power at 4.5 GHz\n",
    "EXACT_WORKLOAD_OVERHEAD_PCT = 0.0032\n",
    "\n",
    "# Derive CIAS power in W from that percentage and the median workload power\n",
    "cias_power_W = (EXACT_WORKLOAD_OVERHEAD_PCT / 100.0) * median_workload_power_W\n",
    "\n",
    "# Compute idle overhead by comparing same CIAS power against idle baseline\n",
    "EXACT_IDLE_OVERHEAD_PCT = (cias_power_W / IDLE_POWER_W) * 100.0\n",
    "\n",
    "# ============================================================\n",
    "# 2) Build comparison table (EXACT vs OCTANE vs E-SCOUT)\n",
    "# ============================================================\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"method\": \"EXACT (CIAS)\",\n",
    "        \"n_features\": 15,\n",
    "        \"area_overhead_pct\": EXACT_AREA_OVERHEAD_PCT,\n",
    "        \"power_idle_overhead_pct\": EXACT_IDLE_OVERHEAD_PCT,\n",
    "        \"power_workload_overhead_pct\": EXACT_WORKLOAD_OVERHEAD_PCT,\n",
    "    },\n",
    "    {\n",
    "        \"method\": \"OCTANE\",\n",
    "        \"n_features\": 227,           # ~active subset on Setup B\n",
    "        \"area_overhead_pct\": 1.2,    # paper\n",
    "        \"power_idle_overhead_pct\": 2.6,\n",
    "        \"power_workload_overhead_pct\": 0.9,  # avg during workloads\n",
    "    },\n",
    "    {\n",
    "        \"method\": \"E-SCOUT\",\n",
    "        \"n_features\": 230,           # top 50% of 460 features\n",
    "        \"area_overhead_pct\": 2.2,\n",
    "        \"power_idle_overhead_pct\": 1.0,      # idle overhead\n",
    "        \"power_workload_overhead_pct\": np.nan,  # not explicitly reported\n",
    "    },\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Print a clean table (no figure generation)\n",
    "# ============================================================\n",
    "\n",
    "# Add a simple derived ratio (optional, but often useful)\n",
    "df[\"area_to_idle_power_ratio\"] = df[\"area_overhead_pct\"] / df[\"power_idle_overhead_pct\"].replace(0, np.nan)\n",
    "\n",
    "# Friendly formatting for console output\n",
    "df_print = df.copy()\n",
    "\n",
    "# Format numeric columns as strings with units\n",
    "df_print[\"area_overhead_pct\"] = df_print[\"area_overhead_pct\"].map(lambda x: f\"{x:.6f}%\")\n",
    "df_print[\"power_idle_overhead_pct\"] = df_print[\"power_idle_overhead_pct\"].map(lambda x: f\"{x:.6f}%\")\n",
    "df_print[\"power_workload_overhead_pct\"] = df_print[\"power_workload_overhead_pct\"].map(\n",
    "    lambda x: \"N/A\" if pd.isna(x) else f\"{x:.6f}%\"\n",
    ")\n",
    "df_print[\"area_to_idle_power_ratio\"] = df_print[\"area_to_idle_power_ratio\"].map(\n",
    "    lambda x: \"N/A\" if pd.isna(x) else f\"{x:.3f}\"\n",
    ")\n",
    "\n",
    "# Reorder columns for readability\n",
    "df_print = df_print[\n",
    "    [\n",
    "        \"method\",\n",
    "        \"n_features\",\n",
    "        \"area_overhead_pct\",\n",
    "        \"power_idle_overhead_pct\",\n",
    "        \"power_workload_overhead_pct\",\n",
    "        \"area_to_idle_power_ratio\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"HARDWARE OVERHEAD COMPARISON SUMMARY (TABLE ONLY)\")\n",
    "print(\"=\" * 110)\n",
    "print(df_print.to_string(index=False))\n",
    "print(\"=\" * 110)\n",
    "\n",
    "# ============================================================\n",
    "# 4) Optional: save to CSV for Overleaf / paper tables\n",
    "# ============================================================\n",
    "\n",
    "out_csv = \"hardware_overhead_comparison_table.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved table to: {out_csv}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5) Optional: short key findings (text only)\n",
    "# ============================================================\n",
    "\n",
    "exact_vs_octane_area = df.loc[df[\"method\"] == \"OCTANE\", \"area_overhead_pct\"].values[0] / df.loc[\n",
    "    df[\"method\"] == \"EXACT (CIAS)\", \"area_overhead_pct\"\n",
    "].values[0]\n",
    "exact_vs_escout_area = df.loc[df[\"method\"] == \"E-SCOUT\", \"area_overhead_pct\"].values[0] / df.loc[\n",
    "    df[\"method\"] == \"EXACT (CIAS)\", \"area_overhead_pct\"\n",
    "].values[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"KEY FINDINGS (TEXT ONLY)\")\n",
    "print(\"=\" * 110)\n",
    "print(f\"• EXACT (CIAS) area overhead: {EXACT_AREA_OVERHEAD_PCT:.6f}% (≈{exact_vs_octane_area:,.0f}× lower than OCTANE; ≈{exact_vs_escout_area:,.0f}× lower than E-SCOUT).\")\n",
    "print(f\"• EXACT (CIAS) idle power overhead (derived from workload %): {EXACT_IDLE_OVERHEAD_PCT:.6f}%.\")\n",
    "print(f\"• OCTANE: {df.loc[1,'n_features']} features, {df.loc[1,'area_overhead_pct']:.2f}% area, {df.loc[1,'power_idle_overhead_pct']:.2f}% idle power.\")\n",
    "print(f\"• E-SCOUT: {df.loc[2,'n_features']} features, {df.loc[2,'area_overhead_pct']:.2f}% area, {df.loc[2,'power_idle_overhead_pct']:.2f}% idle power (workload power overhead not reported).\")\n",
    "print(\"=\" * 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dde5da-4cf0-4f53-bb75-c184b7173160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "setups = [\"A\", \"B\"]\n",
    "cias_area_mm2 = 0.0030499999999999998  # Same for both setups\n",
    "cpu_die_mm2 = {\"A\": 125.0, \"B\": 215.25}\n",
    "cias_cpu_die_percent = {\n",
    "    \"A\": 0.0024399999999999995,\n",
    "    \"B\": 0.0014169570267131243,\n",
    "}\n",
    "\n",
    "# Convert to lists\n",
    "percents = [cias_cpu_die_percent[s] for s in setups]\n",
    "\n",
    "# High-quality styling for publication\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 14,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"xtick.labelsize\": 13,\n",
    "    \"ytick.labelsize\": 13,\n",
    "    \"font.family\": \"DejaVu Sans\",\n",
    "    \"figure.dpi\": 300,  # High resolution\n",
    "})\n",
    "\n",
    "# Create the figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), constrained_layout=True)\n",
    "\n",
    "# Professional color scheme\n",
    "color_cias = '#2E86AB'  # Professional blue\n",
    "color_percent = '#A23B72'  # Professional purple\n",
    "color_highlight = '#F18F01'  # Accent color\n",
    "\n",
    "# -------------------------------\n",
    "# Left plot: CIAS Area (single bar)\n",
    "# -------------------------------\n",
    "bars_left = ax1.bar(['CIAS Area'], [cias_area_mm2], \n",
    "                   color=color_cias, alpha=0.8, width=0.6,\n",
    "                   edgecolor='black', linewidth=1.2)\n",
    "\n",
    "ax1.set_ylabel('Area (mm²)', fontweight='bold', color=color_cias)\n",
    "ax1.set_title('Absolute CIAS Area\\n(Same for Both Setups)', \n",
    "              fontweight='bold', pad=20)\n",
    "\n",
    "# Value annotation\n",
    "ax1.text(0, cias_area_mm2 * 1.15, f'{cias_area_mm2:.6f} mm²', \n",
    "         ha='center', va='bottom', fontsize=13, fontweight='bold',\n",
    "         color=color_cias, bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                                   facecolor='white', \n",
    "                                   edgecolor=color_cias, \n",
    "                                   alpha=0.9))\n",
    "\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.4, color='gray')\n",
    "ax1.set_ylim(0, cias_area_mm2 * 1.8)\n",
    "\n",
    "# Clean spines\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# -------------------------------\n",
    "# Right plot: Percentage Share\n",
    "# -------------------------------\n",
    "x_pos = np.arange(len(setups))\n",
    "bars_right = ax2.bar(x_pos, percents, \n",
    "                    color=color_percent, alpha=0.8, width=0.6,\n",
    "                    edgecolor='black', linewidth=1.2)\n",
    "\n",
    "ax2.set_xlabel('Setup', fontweight='bold')\n",
    "ax2.set_ylabel('Share of CPU Die Area (%)', fontweight='bold', color=color_percent)\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([f'Setup {s}' for s in setups])\n",
    "ax2.set_title('CIAS Die Area Overhead', fontweight='bold', pad=20)\n",
    "\n",
    "# Value annotations with percentage formatting\n",
    "for i, (rect, val, setup) in enumerate(zip(bars_right, percents, setups)):\n",
    "    height = rect.get_height()\n",
    "    die_size = cpu_die_mm2[setup]\n",
    "    \n",
    "    # Main percentage value\n",
    "    ax2.text(rect.get_x() + rect.get_width()/2., height * 1.25,\n",
    "             f'{val:.4%}',  # Format as percentage\n",
    "             ha='center', va='bottom', fontsize=13, fontweight='bold',\n",
    "             color=color_percent,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                     facecolor='white', \n",
    "                     edgecolor=color_percent, \n",
    "                     alpha=0.9))\n",
    "    \n",
    "    # CPU die size info\n",
    "    ax2.text(rect.get_x() + rect.get_width()/2., -max(percents) * 0.15,\n",
    "             f'CPU Die: {die_size} mm²',\n",
    "             ha='center', va='top', fontsize=11, style='italic',\n",
    "             color='dimgray')\n",
    "\n",
    "ax2.grid(axis='y', linestyle='--', alpha=0.4, color='gray')\n",
    "ax2.set_ylim(-max(percents) * 0.25, max(percents) * 1.6)\n",
    "\n",
    "# Clean spines\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "# Overall title\n",
    "plt.suptitle('CIAS Area Analysis: Absolute Size and Relative Overhead', \n",
    "             fontsize=18, fontweight='bold', y=1.02)\n",
    "\n",
    "# Explanatory note\n",
    "fig.text(0.5, 0.01, \n",
    "         'Note: CIAS area is identical in both setups (0.00305 mm²), but represents different overhead percentages due to different CPU die sizes.',\n",
    "         ha='center', fontsize=11, style='italic', color='dimgray')\n",
    "\n",
    "# Save as high-quality PNG\n",
    "plt.savefig('cias_analysis_high_quality.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none')\n",
    "plt.savefig('cias_analysis_presentation.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='white', edgecolor='none', transparent=False)\n",
    "\n",
    "print(\"High-quality PNG files saved:\")\n",
    "print(\"- cias_analysis_high_quality.png\")\n",
    "print(\"- cias_analysis_presentation.png\")\n",
    "\n",
    "# Also create a version with transparent background for presentations\n",
    "plt.savefig('cias_analysis_transparent.png', dpi=300, bbox_inches='tight', \n",
    "            facecolor='none', edgecolor='none', transparent=True)\n",
    "print(\"- cias_analysis_transparent.png (transparent background)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e0455-2eec-483c-8cf2-1da0f28d8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patheffects as pe  # for black outline on lines\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Global plotting style\n",
    "# ---------------------------------------------------------------------------\n",
    "plt.rcParams[\"xtick.labelsize\"] = 16\n",
    "plt.rcParams[\"ytick.labelsize\"] = 16\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "plt.rcParams[\"axes.titlesize\"] = 18\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------------------------------------------\n",
    "df_a_workload = pd.read_csv(\n",
    "    \"./results/SETUP_A_EXACT_summary_per_workload.csv\"\n",
    ")\n",
    "df_b_workload = pd.read_csv(\n",
    "    \"./results/SETUP_B_EXACT_summary_per_workload.csv\"\n",
    ")\n",
    "\n",
    "# Filter for 5-fold cross-validation only\n",
    "df_a_workload_5fold = df_a_workload[df_a_workload[\"n_splits\"] == 5]\n",
    "df_b_workload_5fold = df_b_workload[df_b_workload[\"n_splits\"] == 5]\n",
    "\n",
    "# Determine window sizes from data (works for 250..1000 or 50..1000)\n",
    "window_sizes = sorted(\n",
    "    set(df_a_workload_5fold[\"window_size\"].unique())\n",
    "    .union(set(df_b_workload_5fold[\"window_size\"].unique()))\n",
    ")\n",
    "x_pos = np.arange(len(window_sizes))\n",
    "\n",
    "# Slightly lighter but still dark colors for each setup\n",
    "setup_a_color = \"#1E88E5\"  # Medium-dark blue\n",
    "setup_b_color = \"#8B0000\"  # Dark red\n",
    "\n",
    "# ============================================================================\n",
    "# FIGURE: MCC, Balanced Accuracy, and Brier vs Window Length\n",
    "# ============================================================================\n",
    "metrics = [\n",
    "    (\"mcc\", \"MCC\", 0.5, 1.0),\n",
    "    (\"bal_acc\", \"Balanced Accuracy\", 0.5, 1.0),\n",
    "    (\"brier\", \"Brier Score\", None, None),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(metrics), ncols=1, figsize=(12, 12), sharex=True\n",
    ")\n",
    "\n",
    "for ax, (metric_col, metric_label, y_min, y_max) in zip(axes, metrics):\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Scatter points (per workload)\n",
    "    # -----------------------------------------------------------------------\n",
    "    for idx, ws in enumerate(window_sizes):\n",
    "        ws_data_a = df_a_workload_5fold[df_a_workload_5fold[\"window_size\"] == ws]\n",
    "        ws_data_b = df_b_workload_5fold[df_b_workload_5fold[\"window_size\"] == ws]\n",
    "\n",
    "        # Setup A scatter\n",
    "        if not ws_data_a.empty and metric_col in ws_data_a.columns:\n",
    "            jitter = np.random.uniform(-0.05, 0.05, size=len(ws_data_a))\n",
    "            ax.scatter(\n",
    "                [idx + j for j in jitter],\n",
    "                ws_data_a[metric_col].values,\n",
    "                facecolor=setup_a_color,\n",
    "                edgecolor=\"black\",        # thin black border around markers\n",
    "                alpha=0.7,\n",
    "                s=55,\n",
    "                linewidth=0.8,\n",
    "            )\n",
    "\n",
    "        # Setup B scatter\n",
    "        if not ws_data_b.empty and metric_col in ws_data_b.columns:\n",
    "            jitter = np.random.uniform(-0.05, 0.05, size=len(ws_data_b))\n",
    "            ax.scatter(\n",
    "                [idx + j for j in jitter],\n",
    "                ws_data_b[metric_col].values,\n",
    "                facecolor=setup_b_color,\n",
    "                edgecolor=\"black\",        # thin black border around markers\n",
    "                alpha=0.7,\n",
    "                s=55,\n",
    "                linewidth=0.8,\n",
    "            )\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Window-averaged lines (connected across W) with black outline\n",
    "    # -----------------------------------------------------------------------\n",
    "    if metric_col in df_a_workload_5fold.columns:\n",
    "        avg_A = (\n",
    "            df_a_workload_5fold.groupby(\"window_size\")[metric_col]\n",
    "            .mean()\n",
    "            .reindex(window_sizes)\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_pos,\n",
    "            avg_A.values,\n",
    "            color=setup_a_color,\n",
    "            linewidth=2.5,\n",
    "            marker=\"o\",\n",
    "            markersize=7,\n",
    "            markerfacecolor=setup_a_color,\n",
    "            markeredgecolor=\"black\",\n",
    "            markeredgewidth=0.8,\n",
    "            label=\"Setup A (Window Average)\",\n",
    "            path_effects=[\n",
    "                pe.Stroke(linewidth=3.5, foreground=\"black\"),\n",
    "                pe.Normal(),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    if metric_col in df_b_workload_5fold.columns:\n",
    "        avg_B = (\n",
    "            df_b_workload_5fold.groupby(\"window_size\")[metric_col]\n",
    "            .mean()\n",
    "            .reindex(window_sizes)\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_pos,\n",
    "            avg_B.values,\n",
    "            color=setup_b_color,\n",
    "            linewidth=2.5,\n",
    "            linestyle=\"--\",\n",
    "            marker=\"s\",\n",
    "            markersize=7,\n",
    "            markerfacecolor=setup_b_color,\n",
    "            markeredgecolor=\"black\",\n",
    "            markeredgewidth=0.8,\n",
    "            label=\"Setup B (Window Average)\",\n",
    "            path_effects=[\n",
    "                pe.Stroke(linewidth=3.5, foreground=\"black\"),\n",
    "                pe.Normal(),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # Axis labels and limits\n",
    "    ax.set_ylabel(metric_label, fontsize=16, fontweight=\"bold\")\n",
    "    ax.grid(True, alpha=0.3, color=\"#AAAAAA\", linestyle=\"-\", linewidth=1.0)\n",
    "\n",
    "    if y_min is not None and y_max is not None:\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        yticks = np.linspace(y_min, y_max, 6)\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.set_yticklabels([f\"{y:.1f}\" for y in yticks])\n",
    "    else:\n",
    "        # For Brier, use data-driven limits with a bit of margin\n",
    "        all_vals = []\n",
    "        if metric_col in df_a_workload_5fold.columns:\n",
    "            all_vals.extend(df_a_workload_5fold[metric_col].values)\n",
    "        if metric_col in df_b_workload_5fold.columns:\n",
    "            all_vals.extend(df_b_workload_5fold[metric_col].values)\n",
    "        if len(all_vals) > 0:\n",
    "            vmin = min(all_vals)\n",
    "            vmax = max(all_vals)\n",
    "            margin = 0.1 * (vmax - vmin) if vmax > vmin else 0.01\n",
    "            ax.set_ylim(max(0.0, vmin - margin), vmax + margin)\n",
    "\n",
    "# Shared X-axis setup\n",
    "axes[-1].set_xlabel(\"Window Size ($W$)\", fontsize=16, fontweight=\"bold\")\n",
    "axes[-1].set_xticks(x_pos)\n",
    "axes[-1].set_xticklabels(window_sizes)\n",
    "\n",
    "for ax in axes:\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"#444444\")\n",
    "        spine.set_linewidth(2)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Window-Level Performance vs Window Size ($W$)\\n\"\n",
    "    \"MCC, Balanced Accuracy, and Brier Score\",\n",
    "    fontsize=20,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.02,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"window_metrics_plot_no_legend.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# LEGEND ONLY (two horizontal lines, two entries each)\n",
    "# ============================================================================\n",
    "fig2 = plt.figure(figsize=(10, 3))   # medium width, a bit taller for 2 rows\n",
    "ax2 = fig2.add_subplot(111)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        marker=\"o\", color=\"w\", markerfacecolor=setup_a_color,\n",
    "        markeredgecolor=\"black\", markersize=10,\n",
    "        label=\"Setup A (Workloads)\", markeredgewidth=0.8,\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        color=setup_a_color, linewidth=2.5, marker=\"o\", markersize=7,\n",
    "        markerfacecolor=setup_a_color, markeredgecolor=\"black\",\n",
    "        markeredgewidth=0.8,\n",
    "        label=\"Setup A (Window Average)\",\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        marker=\"o\", color=\"w\", markerfacecolor=setup_b_color,\n",
    "        markeredgecolor=\"black\", markersize=10,\n",
    "        label=\"Setup B (Workloads)\", markeredgewidth=0.8,\n",
    "    ),\n",
    "    Line2D(\n",
    "        [0], [0],\n",
    "        color=setup_b_color, linewidth=2.5, linestyle=\"--\",\n",
    "        marker=\"s\", markersize=7,\n",
    "        markerfacecolor=setup_b_color, markeredgecolor=\"black\",\n",
    "        markeredgewidth=0.8,\n",
    "        label=\"Setup B (Window Average)\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "ax2.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"center\",\n",
    "    ncol=2,                 # 2 columns → 2 items per row\n",
    "    fontsize=16,\n",
    "    framealpha=0.95,\n",
    "    edgecolor=\"black\",\n",
    "    frameon=True,\n",
    "    handlelength=3,\n",
    "    handletextpad=1.2,\n",
    "    columnspacing=2.0,\n",
    ")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"window_metrics_legend.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    "    facecolor=\"white\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff14e90-6415-4651-b755-595bee510193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}